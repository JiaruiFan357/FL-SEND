{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrmEzVwjFI0t"
      },
      "source": [
        "# Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m1q-zyK-xu5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8060da2d-425f-44e5-f591-2032bd7c3fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: flwr 1.15.2\n",
            "Uninstalling flwr-1.15.2:\n",
            "  Successfully uninstalled flwr-1.15.2\n",
            "Found existing installation: ray 2.31.0\n",
            "Uninstalling ray-2.31.0:\n",
            "  Successfully uninstalled ray-2.31.0\n",
            "Collecting ray\n",
            "  Using cached ray-2.43.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting flwr[simulation]\n",
            "  Using cached flwr-1.15.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: cryptography<44.0.0,>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (43.0.3)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.70.0)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.0.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.26.4)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (4.25.6)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (3.21.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (6.0.2)\n",
            "Collecting ray\n",
            "  Using cached ray-2.31.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray) (3.17.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray) (24.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray) (1.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44.0.0,>=43.0.1->flwr[simulation]) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (4.12.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (0.23.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->flwr[simulation]) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation]) (0.1.2)\n",
            "Using cached ray-2.31.0-cp311-cp311-manylinux2014_x86_64.whl (66.7 MB)\n",
            "Using cached flwr-1.15.2-py3-none-any.whl (531 kB)\n",
            "Installing collected packages: ray, flwr\n",
            "Successfully installed flwr-1.15.2 ray-2.31.0\n",
            "Requirement already satisfied: pyannote.metrics in /usr/local/lib/python3.11/dist-packages (3.2.1)\n",
            "Requirement already satisfied: pyannote.core>=4.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (5.1.3)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (1.6.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (3.10.0)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.metrics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.metrics) (2025.1)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=4.1->pyannote.metrics) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=4.1->pyannote.metrics) (4.12.2)\n",
            "Requirement already satisfied: pyYAML>=3.12 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics) (6.0.2)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics) (0.12.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.1->pyannote.metrics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (0.1.2)\n",
            "Requirement already satisfied: pyannote.core in /usr/local/lib/python3.11/dist-packages (5.0.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core) (4.12.2)\n",
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (2.32.3)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain) (0.18.10)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y flwr ray\n",
        "!pip install -U \"flwr[simulation]\" ray\n",
        "!pip install pyannote.metrics\n",
        "!pip install pyannote.core\n",
        "!pip install speechbrain\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-xT8bmDxmtx",
        "outputId": "6d3c4f5d-270a-453f-fe31-3215effe3a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load AMI dataset and group by meeting ID\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"edinburghcstr/ami\", \"ihm\")\n",
        "\n",
        "def group_by_meeting(dataset_split):\n",
        "    grouped = {}\n",
        "    for sample in dataset_split:\n",
        "        meeting_id = sample[\"meeting_id\"]\n",
        "        grouped.setdefault(meeting_id, []).append(sample)\n",
        "    return grouped\n",
        "\n",
        "grouped_train = group_by_meeting(dataset[\"train\"].select(range(5000)))\n",
        "grouped_validation = group_by_meeting(dataset[\"validation\"].select(range(5000)))\n",
        "grouped_test = group_by_meeting(dataset[\"test\"].select(range(5000)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUSdqcgDxjdU",
        "outputId": "b479a36f-7755-4c0d-84ee-2975f9aa7a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (2.32.3)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain) (0.18.10)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install speechbrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5fMajSI4OAY",
        "outputId": "51b35294-10f4-4870-d52d-0f7f22d901cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  cm = get_cmap(\"Set1\")\n",
            "<ipython-input-4-0ce21e2d0acc>:21: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
            "  from speechbrain.pretrained import EncoderClassifier\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import flwr as fl\n",
        "from flwr.client import NumPyClient\n",
        "from flwr.common import Context\n",
        "from pyannote.core import Segment, Annotation\n",
        "from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "from speechbrain.pretrained import EncoderClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjXre3MgwXDe",
        "outputId": "78bd1660-6b16-48cc-9c58-49bada1bd3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  stats = torch.load(path, map_location=device)\n",
            "<ipython-input-5-e83a4059dbae>:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()  # ✅ Mixed Precision Scaling\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import librosa\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "from torch.optim import Adam\n",
        "from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "from scipy.stats import mode\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# **Set device**\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# **Load Pretrained Speaker Encoder (ECAPA-TDNN)**\n",
        "speaker_encoder = EncoderClassifier.from_hparams(\n",
        "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "    run_opts={\"device\": device}\n",
        ").to(device)\n",
        "\n",
        "# **Freeze the speaker encoder**\n",
        "for param in speaker_encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# **Function to extract speaker embeddings**\n",
        "def extract_speaker_embedding(features):\n",
        "    \"\"\"Extracts speaker embeddings using ECAPA-TDNN.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        embeddings = speaker_encoder.encode_batch(features)\n",
        "        return embeddings.squeeze(1)  # Remove unnecessary dimension\n",
        "\n",
        "# **Power-Set Encoding Function**\n",
        "def power_set_encoding(labels):\n",
        "    \"\"\"Encodes multi-label speaker activation into a single integer using power-set encoding.\"\"\"\n",
        "    return sum([l * (2 ** i) for i, l in enumerate(labels) if l in [0, 1]])\n",
        "\n",
        "# **Overlapping Speech Simulation**\n",
        "def simulate_overlap(grouped_data, num_speakers=2, duration=10, sampling_rate=16000):\n",
        "    overlapping_segments = []\n",
        "    labels = []\n",
        "    for meeting_id, samples in grouped_data.items():\n",
        "        speakers = {sample[\"speaker_id\"]: [] for sample in samples}\n",
        "        for sample in samples:\n",
        "            speakers[sample[\"speaker_id\"]].append(sample)\n",
        "        if len(speakers) < num_speakers:\n",
        "            continue\n",
        "        for _ in range(50):\n",
        "            chosen_speakers = random.sample(list(speakers.keys()), num_speakers)\n",
        "            combined_signal = None\n",
        "            speaker_label = [0] * len(speakers)\n",
        "            for speaker_id in chosen_speakers:\n",
        "                sample = random.choice(speakers[speaker_id])\n",
        "                signal = sample[\"audio\"][\"array\"]\n",
        "                if len(signal) > duration * sampling_rate:\n",
        "                    signal = signal[: duration * sampling_rate]\n",
        "                else:\n",
        "                    signal = np.pad(signal, (0, duration * sampling_rate - len(signal)), mode=\"constant\")\n",
        "                if combined_signal is None:\n",
        "                    combined_signal = signal\n",
        "                else:\n",
        "                    combined_signal += signal\n",
        "                speaker_label[list(speakers.keys()).index(speaker_id)] = 1\n",
        "            if combined_signal is not None and np.max(np.abs(combined_signal)) > 0:\n",
        "                combined_signal = combined_signal / np.max(np.abs(combined_signal))\n",
        "            else:\n",
        "                continue\n",
        "            overlapping_segments.append(combined_signal)\n",
        "            labels.append(power_set_encoding(speaker_label))\n",
        "\n",
        "    # ✅ Debug: Print the first few labels to check if overlapping speech is simulated correctly\n",
        "    print(\"🔹 Sample labels from train set (Power-Set Encoded):\")\n",
        "    for i in range(min(10, len(labels))):  # Print up to 10 samples\n",
        "        print(labels[i])\n",
        "\n",
        "    return overlapping_segments, labels\n",
        "\n",
        "\n",
        "# **Feature Extraction (Log-Mel Spectrograms)**\n",
        "def extract_features_batch(segments, sr=16000, n_mels=80, win_length=0.025, hop_length=0.01, max_frames=None):\n",
        "    features = []\n",
        "    win_length_samples = int(win_length * sr)\n",
        "    hop_length_samples = int(hop_length * sr)\n",
        "\n",
        "    for segment in segments:\n",
        "        mel_spec = librosa.feature.melspectrogram(\n",
        "            y=segment, sr=sr, n_mels=n_mels, win_length=win_length_samples, hop_length=hop_length_samples\n",
        "        )\n",
        "        log_mel = librosa.power_to_db(mel_spec)\n",
        "\n",
        "        if max_frames:\n",
        "            log_mel = log_mel[:, :max_frames] if log_mel.shape[1] > max_frames else np.pad(\n",
        "                log_mel, ((0, 0), (0, max_frames - log_mel.shape[1])), mode=\"constant\"\n",
        "            )\n",
        "\n",
        "        features.append(log_mel.T)\n",
        "\n",
        "    features = np.array(features, dtype=np.float32)\n",
        "\n",
        "    return torch.tensor(features, dtype=torch.float32)  # ✅ Corrected tensor conversion\n",
        "\n",
        "class OverlappingSpeechDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        # Ensure label shape is [time] to match outputs\n",
        "        label = label.expand(feature.shape[0])\n",
        "\n",
        "        return feature, label\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()  # ✅ Mixed Precision Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFS4M_9Jx64p",
        "outputId": "733b1604-4166-44e3-d829-fd98dd10ea3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-0b7e27721769>:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()  # ✅ Mixed Precision Scaling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Sample labels from train set (Power-Set Encoded):\n",
            "12\n",
            "5\n",
            "17\n",
            "24\n",
            "10\n",
            "10\n",
            "12\n",
            "10\n",
            "20\n",
            "10\n",
            "🔹 Sample labels from train set (Power-Set Encoded):\n",
            "12\n",
            "10\n",
            "3\n",
            "10\n",
            "9\n",
            "9\n",
            "5\n",
            "10\n",
            "9\n",
            "10\n",
            "🔹 Sample labels from train set (Power-Set Encoded):\n",
            "6\n",
            "10\n",
            "3\n",
            "5\n",
            "9\n",
            "9\n",
            "5\n",
            "10\n",
            "3\n",
            "12\n",
            "🔹 Unique Labels in Training Set: {3, 5, 6, 9, 10, 12, 17, 18, 20, 24}\n",
            "🔹 Label Distribution:\n",
            "Label: 12, Binary: 01100, Count: 22\n",
            "Label: 5, Binary: 00101, Count: 23\n",
            "Label: 17, Binary: 10001, Count: 13\n",
            "Label: 24, Binary: 11000, Count: 15\n",
            "Label: 10, Binary: 01010, Count: 19\n",
            "Label: 20, Binary: 10100, Count: 16\n",
            "Label: 6, Binary: 00110, Count: 30\n",
            "Label: 9, Binary: 01001, Count: 26\n",
            "Label: 18, Binary: 10010, Count: 13\n",
            "Label: 3, Binary: 00011, Count: 23\n",
            "🔹 Label Mapping: {3: 0, 5: 1, 6: 2, 9: 3, 10: 4, 12: 5, 17: 6, 18: 7, 20: 8, 24: 9}\n",
            "🔹 Mapped Training Labels: [5, 1, 6, 9, 4, 4, 5, 4, 8, 4]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import librosa\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "from torch.optim import Adam\n",
        "from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "from scipy.stats import mode\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# **Set device**\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# **Load Pretrained Speaker Encoder (ECAPA-TDNN)**\n",
        "speaker_encoder = EncoderClassifier.from_hparams(\n",
        "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "    run_opts={\"device\": device}\n",
        ").to(device)\n",
        "\n",
        "# **Freeze the speaker encoder**\n",
        "for param in speaker_encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# **Function to extract speaker embeddings**\n",
        "def extract_speaker_embedding(features):\n",
        "    \"\"\"Extracts speaker embeddings using ECAPA-TDNN.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        embeddings = speaker_encoder.encode_batch(features)\n",
        "        return embeddings.squeeze(1)  # Remove unnecessary dimension\n",
        "\n",
        "# **Power-Set Encoding Function**\n",
        "def power_set_encoding(labels):\n",
        "    \"\"\"Encodes multi-label speaker activation into a single integer using power-set encoding.\"\"\"\n",
        "    return sum([l * (2 ** i) for i, l in enumerate(labels) if l in [0, 1]])\n",
        "\n",
        "# **Overlapping Speech Simulation**\n",
        "def simulate_overlap(grouped_data, num_speakers=2, duration=10, sampling_rate=16000):\n",
        "    overlapping_segments = []\n",
        "    labels = []\n",
        "    for meeting_id, samples in grouped_data.items():\n",
        "        speakers = {sample[\"speaker_id\"]: [] for sample in samples}\n",
        "        for sample in samples:\n",
        "            speakers[sample[\"speaker_id\"]].append(sample)\n",
        "        if len(speakers) < num_speakers:\n",
        "            continue\n",
        "        for _ in range(50):\n",
        "            chosen_speakers = random.sample(list(speakers.keys()), num_speakers)\n",
        "            combined_signal = None\n",
        "            speaker_label = [0] * len(speakers)\n",
        "            for speaker_id in chosen_speakers:\n",
        "                sample = random.choice(speakers[speaker_id])\n",
        "                signal = sample[\"audio\"][\"array\"]\n",
        "                if len(signal) > duration * sampling_rate:\n",
        "                    signal = signal[: duration * sampling_rate]\n",
        "                else:\n",
        "                    signal = np.pad(signal, (0, duration * sampling_rate - len(signal)), mode=\"constant\")\n",
        "                if combined_signal is None:\n",
        "                    combined_signal = signal\n",
        "                else:\n",
        "                    combined_signal += signal\n",
        "                speaker_label[list(speakers.keys()).index(speaker_id)] = 1\n",
        "            if combined_signal is not None and np.max(np.abs(combined_signal)) > 0:\n",
        "                combined_signal = combined_signal / np.max(np.abs(combined_signal))\n",
        "            else:\n",
        "                continue\n",
        "            overlapping_segments.append(combined_signal)\n",
        "            labels.append(power_set_encoding(speaker_label))\n",
        "\n",
        "    # ✅ Debug: Print the first few labels to check if overlapping speech is simulated correctly\n",
        "    print(\"🔹 Sample labels from train set (Power-Set Encoded):\")\n",
        "    for i in range(min(10, len(labels))):  # Print up to 10 samples\n",
        "        print(labels[i])\n",
        "\n",
        "    return overlapping_segments, labels\n",
        "\n",
        "\n",
        "# **Feature Extraction (Log-Mel Spectrograms)**\n",
        "def extract_features_batch(segments, sr=16000, n_mels=80, win_length=0.025, hop_length=0.01, max_frames=None):\n",
        "    features = []\n",
        "    win_length_samples = int(win_length * sr)\n",
        "    hop_length_samples = int(hop_length * sr)\n",
        "\n",
        "    for segment in segments:\n",
        "        mel_spec = librosa.feature.melspectrogram(\n",
        "            y=segment, sr=sr, n_mels=n_mels, win_length=win_length_samples, hop_length=hop_length_samples\n",
        "        )\n",
        "        log_mel = librosa.power_to_db(mel_spec)\n",
        "\n",
        "        if max_frames:\n",
        "            log_mel = log_mel[:, :max_frames] if log_mel.shape[1] > max_frames else np.pad(\n",
        "                log_mel, ((0, 0), (0, max_frames - log_mel.shape[1])), mode=\"constant\"\n",
        "            )\n",
        "\n",
        "        features.append(log_mel.T)\n",
        "\n",
        "    features = np.array(features, dtype=np.float32)\n",
        "\n",
        "    return torch.tensor(features, dtype=torch.float32)  # ✅ Corrected tensor conversion\n",
        "\n",
        "class OverlappingSpeechDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        # Ensure label shape is [time] to match outputs\n",
        "        label = label.expand(feature.shape[0])\n",
        "\n",
        "        return feature, label\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()  # ✅ Mixed Precision Scaling\n",
        "\n",
        "# **Training Execution**\n",
        "num_speakers = 5\n",
        "\n",
        "# Simulate overlapping speech for training\n",
        "train_segments, train_labels = simulate_overlap(grouped_train)\n",
        "val_segments, val_labels = simulate_overlap(grouped_validation)\n",
        "test_segments, test_labels = simulate_overlap(grouped_test)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "print(\"🔹 Unique Labels in Training Set:\", set(train_labels))\n",
        "print(\"🔹 Label Distribution:\")\n",
        "label_counts = Counter(train_labels)\n",
        "for label, count in label_counts.items():\n",
        "    binary_repr = bin(label)[2:].zfill(num_speakers)  # Convert to binary\n",
        "    print(f\"Label: {label}, Binary: {binary_repr}, Count: {count}\")\n",
        "\n",
        "unique_labels = sorted(set(train_labels + val_labels))  # ✅ Include val_labels\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
        "\n",
        "print(f\"🔹 Label Mapping: {label_to_index}\")\n",
        "\n",
        "num_classes = len(unique_labels)  # ✅ Actual number of classes\n",
        "\n",
        "# Apply mapping to training and validation labels\n",
        "train_labels = [label_to_index[label] for label in train_labels]\n",
        "val_labels = [label_to_index[label] for label in val_labels]\n",
        "\n",
        "print(f\"🔹 Mapped Training Labels: {train_labels[:10]}\")  # Debugging\n",
        "\n",
        "\n",
        "max_frames = int((10 / 0.01))  # 10s duration, 0.01 hop length (10s / 10ms)\n",
        "train_features = extract_features_batch(train_segments, max_frames=max_frames)\n",
        "val_features = extract_features_batch(val_segments, max_frames=max_frames)\n",
        "test_features = extract_features_batch(test_segments, max_frames=max_frames)\n",
        "\n",
        "train_loader = DataLoader(OverlappingSpeechDataset(train_features, train_labels), batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(OverlappingSpeechDataset(val_features, val_labels), batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(OverlappingSpeechDataset(test_features, test_labels), batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xzXfsP82yuuV"
      },
      "outputs": [],
      "source": [
        "# import logging\n",
        "# import time\n",
        "# import flwr as fl\n",
        "\n",
        "# import importlib\n",
        "# import ray\n",
        "# importlib.reload(ray)\n",
        "\n",
        "# from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import librosa\n",
        "# import numpy as np\n",
        "# import random\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from speechbrain.pretrained import EncoderClassifier\n",
        "# from torch.optim import Adam\n",
        "# from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "# from scipy.stats import mode\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# # **Set device**\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # **Load Pretrained Speaker Encoder (ECAPA-TDNN)**\n",
        "# speaker_encoder = EncoderClassifier.from_hparams(\n",
        "#     source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "#     savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "#     run_opts={\"device\": device}\n",
        "# ).to(device)\n",
        "\n",
        "# # **Freeze the speaker encoder**\n",
        "# for param in speaker_encoder.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# # **Function to extract speaker embeddings**\n",
        "# def extract_speaker_embedding(features):\n",
        "#     \"\"\"Extracts speaker embeddings using ECAPA-TDNN.\"\"\"\n",
        "#     with torch.no_grad():\n",
        "#         embeddings = speaker_encoder.encode_batch(features)\n",
        "#         return embeddings.squeeze(1)  # Remove unnecessary dimension\n",
        "\n",
        "# # **Power-Set Encoding Function**\n",
        "# def power_set_encoding(labels):\n",
        "#     \"\"\"Encodes multi-label speaker activation into a single integer using power-set encoding.\"\"\"\n",
        "#     return sum([l * (2 ** i) for i, l in enumerate(labels) if l in [0, 1]])\n",
        "\n",
        "# # **Overlapping Speech Simulation**\n",
        "# def simulate_overlap(grouped_data, num_speakers=2, duration=10, sampling_rate=16000):\n",
        "#     overlapping_segments = []\n",
        "#     labels = []\n",
        "#     for meeting_id, samples in grouped_data.items():\n",
        "#         speakers = {sample[\"speaker_id\"]: [] for sample in samples}\n",
        "#         for sample in samples:\n",
        "#             speakers[sample[\"speaker_id\"]].append(sample)\n",
        "#         if len(speakers) < num_speakers:\n",
        "#             continue\n",
        "#         for _ in range(50):\n",
        "#             chosen_speakers = random.sample(list(speakers.keys()), num_speakers)\n",
        "#             combined_signal = None\n",
        "#             speaker_label = [0] * len(speakers)\n",
        "#             for speaker_id in chosen_speakers:\n",
        "#                 sample = random.choice(speakers[speaker_id])\n",
        "#                 signal = sample[\"audio\"][\"array\"]\n",
        "#                 if len(signal) > duration * sampling_rate:\n",
        "#                     signal = signal[: duration * sampling_rate]\n",
        "#                 else:\n",
        "#                     signal = np.pad(signal, (0, duration * sampling_rate - len(signal)), mode=\"constant\")\n",
        "#                 if combined_signal is None:\n",
        "#                     combined_signal = signal\n",
        "#                 else:\n",
        "#                     combined_signal += signal\n",
        "#                 speaker_label[list(speakers.keys()).index(speaker_id)] = 1\n",
        "#             if combined_signal is not None and np.max(np.abs(combined_signal)) > 0:\n",
        "#                 combined_signal = combined_signal / np.max(np.abs(combined_signal))\n",
        "#             else:\n",
        "#                 continue\n",
        "#             overlapping_segments.append(combined_signal)\n",
        "#             labels.append(power_set_encoding(speaker_label))\n",
        "\n",
        "#     # ✅ Debug: Print the first few labels to check if overlapping speech is simulated correctly\n",
        "#     print(\"🔹 Sample labels from train set (Power-Set Encoded):\")\n",
        "#     for i in range(min(10, len(labels))):  # Print up to 10 samples\n",
        "#         print(labels[i])\n",
        "\n",
        "#     return overlapping_segments, labels\n",
        "\n",
        "\n",
        "# # **Feature Extraction (Log-Mel Spectrograms)**\n",
        "# def extract_features_batch(segments, sr=16000, n_mels=80, win_length=0.025, hop_length=0.01, max_frames=None):\n",
        "#     features = []\n",
        "#     win_length_samples = int(win_length * sr)\n",
        "#     hop_length_samples = int(hop_length * sr)\n",
        "\n",
        "#     for segment in segments:\n",
        "#         mel_spec = librosa.feature.melspectrogram(\n",
        "#             y=segment, sr=sr, n_mels=n_mels, win_length=win_length_samples, hop_length=hop_length_samples\n",
        "#         )\n",
        "#         log_mel = librosa.power_to_db(mel_spec)\n",
        "\n",
        "#         if max_frames:\n",
        "#             log_mel = log_mel[:, :max_frames] if log_mel.shape[1] > max_frames else np.pad(\n",
        "#                 log_mel, ((0, 0), (0, max_frames - log_mel.shape[1])), mode=\"constant\"\n",
        "#             )\n",
        "\n",
        "#         features.append(log_mel.T)\n",
        "\n",
        "#     features = np.array(features, dtype=np.float32)\n",
        "\n",
        "#     return torch.tensor(features, dtype=torch.float32)  # ✅ Corrected tensor conversion\n",
        "\n",
        "# class OverlappingSpeechDataset(Dataset):\n",
        "#     def __init__(self, features, labels):\n",
        "#         self.features = features\n",
        "#         self.labels = labels\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.features)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "#         label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "#         return feature, label\n",
        "\n",
        "# scaler = torch.cuda.amp.GradScaler()  # ✅ Mixed Precision Scaling\n",
        "\n",
        "# # **Training Execution**\n",
        "# num_speakers = 5\n",
        "\n",
        "# # Simulate overlapping speech for training\n",
        "# train_segments, train_labels = simulate_overlap(grouped_train)\n",
        "# val_segments, val_labels = simulate_overlap(grouped_validation)\n",
        "# test_segments, test_labels = simulate_overlap(grouped_test)\n",
        "\n",
        "# from collections import Counter\n",
        "\n",
        "# print(\"🔹 Unique Labels in Training Set:\", set(train_labels))\n",
        "# print(\"🔹 Label Distribution:\")\n",
        "# label_counts = Counter(train_labels)\n",
        "# for label, count in label_counts.items():\n",
        "#     binary_repr = bin(label)[2:].zfill(num_speakers)  # Convert to binary\n",
        "#     print(f\"Label: {label}, Binary: {binary_repr}, Count: {count}\")\n",
        "\n",
        "# unique_labels = sorted(set(train_labels + val_labels))  # ✅ Include val_labels\n",
        "# label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "# index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
        "\n",
        "# print(f\"🔹 Label Mapping: {label_to_index}\")\n",
        "\n",
        "# num_classes = len(unique_labels)  # ✅ Actual number of classes\n",
        "\n",
        "# # Apply mapping to training and validation labels\n",
        "# train_labels = [label_to_index[label] for label in train_labels]\n",
        "# val_labels = [label_to_index[label] for label in val_labels]\n",
        "\n",
        "# print(f\"🔹 Mapped Training Labels: {train_labels[:10]}\")  # Debugging\n",
        "\n",
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# def collate_fn_pad(batch):\n",
        "#     \"\"\"Pads variable-length sequences to the longest in the batch, ensuring consistent batch shapes.\"\"\"\n",
        "#     batch = [b for b in batch if b is not None]  # Remove None samples\n",
        "\n",
        "#     if len(batch) == 0:\n",
        "#         return None, None  # Return empty batch if all are invalid\n",
        "\n",
        "#     features, labels = zip(*batch)\n",
        "\n",
        "#     # ✅ Pad sequences to the maximum length in this batch\n",
        "#     features_padded = pad_sequence(features, batch_first=True, padding_value=0)\n",
        "\n",
        "#     # ✅ Keep labels as scalars (no expansion)\n",
        "#     labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "#     return features_padded, labels\n",
        "\n",
        "\n",
        "# max_frames = int((10 / 0.01))  # 10s duration, 0.01 hop length (10s / 10ms)\n",
        "# train_features = extract_features_batch(train_segments, max_frames=max_frames)\n",
        "# val_features = extract_features_batch(val_segments, max_frames=max_frames)\n",
        "# test_features = extract_features_batch(test_segments, max_frames=max_frames)\n",
        "\n",
        "# train_loader = DataLoader(\n",
        "#     OverlappingSpeechDataset(train_features, train_labels),\n",
        "#     batch_size=16,\n",
        "#     shuffle=True,\n",
        "#     collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        "# )\n",
        "\n",
        "# val_loader = DataLoader(\n",
        "#     OverlappingSpeechDataset(val_features, val_labels),\n",
        "#     batch_size=16,\n",
        "#     shuffle=False,\n",
        "#     collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        "# )\n",
        "\n",
        "# test_loader = DataLoader(\n",
        "#     OverlappingSpeechDataset(test_features, test_labels),\n",
        "#     batch_size=16,\n",
        "#     shuffle=False,\n",
        "#     collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        "# )\n",
        "\n",
        "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # ✅ Define `speaker_encoder` correctly\n",
        "# speaker_encoder = EncoderClassifier.from_hparams(\n",
        "#     source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "#     savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "#     run_opts={\"device\": DEVICE}\n",
        "# ).to(DEVICE)\n",
        "\n",
        "# # **SEND Model**\n",
        "# class SpeechEncoder(nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim, num_layers):\n",
        "#         super().__init__()\n",
        "#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x, _ = self.lstm(x)\n",
        "#         return x\n",
        "\n",
        "# class SEND(nn.Module):\n",
        "#     def __init__(self, input_dim, speaker_dim, hidden_dim, num_layers, num_speakers):\n",
        "#         super().__init__()\n",
        "#         self.speech_encoder = SpeechEncoder(input_dim, hidden_dim, num_layers)\n",
        "#         self.speaker_encoder = speaker_encoder.encode_batch\n",
        "\n",
        "#         self.feature_projection = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n",
        "#         self.context_independent = nn.Linear(hidden_dim * 2, num_speakers)\n",
        "#         self.context_dependent = nn.TransformerEncoder(nn.TransformerEncoderLayer(hidden_dim * 2, 4), num_layers)\n",
        "#         self.match_projection = nn.Linear(hidden_dim * 2, num_speakers)\n",
        "#         self.post_net = nn.Linear(hidden_dim * 2, 2 ** num_speakers)  # Ensure input matches hidden_dim * 2\n",
        "\n",
        "#     def forward(self, speech):\n",
        "#         # Ensure correct shape\n",
        "#         if speech.dim() == 4:\n",
        "#             speech = speech.squeeze(1)\n",
        "\n",
        "#         speech_features = self.speech_encoder(speech)\n",
        "#         # print(f\"🔹 Speech features shape after LSTM: {speech_features.shape}\")  # [16, 29, 512]\n",
        "\n",
        "#         speech_features = self.feature_projection(speech_features)\n",
        "#         # print(f\"🔹 Projected speech features shape: {speech_features.shape}\")  # [16, 29, 512]\n",
        "\n",
        "#         # **Apply mean pooling across time dimension (sequence length 29)**\n",
        "#         pooled_features = torch.mean(speech_features, dim=1)  # [16, 512]\n",
        "#         # print(f\"🔹 Pooled features shape: {pooled_features.shape}\")  # [16, 512]\n",
        "\n",
        "#         # Ensure output matches batch size\n",
        "#         output = self.post_net(pooled_features)  # [16, num_classes]\n",
        "#         # print(f\"🔹 Model output shape: {output.shape}\")  # Should be [16, 2**num_speakers]\n",
        "\n",
        "#         return output\n",
        "\n",
        "# model = SEND(input_dim=80, speaker_dim=512, hidden_dim=256, num_layers=4, num_speakers=num_speakers).to(DEVICE)\n",
        "\n",
        "# class FLClient(NumPyClient):\n",
        "#     def __init__(self, model, train_loader, test_loader):\n",
        "#         os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # ✅ Force CPU globally\n",
        "#         self.device = torch.device(\"cpu\")  # ✅ Force CPU for PyTorch\n",
        "#         logging.info(f\"Using device: {self.device}\")\n",
        "#         self.model = model.to(self.device)  # ✅ Move model to CPU\n",
        "#         self.train_loader = train_loader\n",
        "#         self.test_loader = test_loader\n",
        "#         self.optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "#         self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#     def get_parameters(self, config=None):\n",
        "#         return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "#     def set_parameters(self, parameters):\n",
        "#         state_dict = {k: torch.tensor(v).to(self.device) for k, v in zip(self.model.state_dict().keys(), parameters)}\n",
        "#         self.model.load_state_dict(state_dict)\n",
        "#         self.model.to(self.device)  # Ensure model is on the right device\n",
        "\n",
        "#     def fit(self, parameters, config):\n",
        "#       self.set_parameters(parameters)\n",
        "#       self.model.train()\n",
        "\n",
        "#       logging.info(f\"Training on {self.device}...\")\n",
        "#       for epoch in range(2):\n",
        "#           for batch_idx, (features, labels) in enumerate(self.train_loader):\n",
        "#               features, labels = features.to(self.device), labels.to(self.device)\n",
        "\n",
        "#               # 🔹 Debug shape mismatch\n",
        "#               print(f\"Batch {batch_idx} - Feature shape: {features.shape}, Label shape: {labels.shape}\")\n",
        "\n",
        "#               # 🔹 Print sample data for debugging\n",
        "#               print(f\"Sample labels: {labels[:5]}\")  # Check label values\n",
        "\n",
        "\n",
        "#               self.optimizer.zero_grad()\n",
        "#               outputs = self.model(features)\n",
        "\n",
        "#               # 🔹 Ensure labels match batch size\n",
        "#               labels = labels.view(-1)  # Flatten labels if needed\n",
        "#               print(f\"Fixed Labels Shape: {labels.shape}\")  # Should match outputs.shape[0]\n",
        "#               print(f\"Outputs shape: {outputs.shape}, Labels shape: {labels.shape}\")\n",
        "\n",
        "#               loss = self.criterion(outputs, labels.long())\n",
        "#               loss.backward()\n",
        "#               self.optimizer.step()\n",
        "\n",
        "#       return self.get_parameters(), len(self.train_loader.dataset), {}\n",
        "\n",
        "\n",
        "#     def evaluate(self, parameters, config):\n",
        "#         self.set_parameters(parameters)\n",
        "#         self.model.eval()\n",
        "\n",
        "#         total_loss = 0\n",
        "#         correct = 0\n",
        "#         total = 0\n",
        "#         with torch.no_grad():\n",
        "#             for batch_idx, (features, labels) in enumerate(self.test_loader):\n",
        "#                 features, labels = features.to(self.device), labels.to(self.device)\n",
        "#                 outputs = self.model(features)\n",
        "\n",
        "#                 labels = labels.long()\n",
        "#                 loss = self.criterion(outputs, labels)\n",
        "#                 total_loss += loss.item()\n",
        "#                 preds = torch.argmax(outputs, dim=-1)\n",
        "#                 correct += (preds == labels).sum().item()\n",
        "#                 total += labels.numel()\n",
        "\n",
        "#                 # ✅ Add debug logging for evaluation\n",
        "#                 logging.info(f\"🔹 Evaluation Batch {batch_idx}\")\n",
        "#                 logging.info(f\"🔹 Predictions: {preds[:5]}\")\n",
        "#                 logging.info(f\"🔹 Ground Truth: {labels[:5]}\")\n",
        "#                 logging.info(f\"🔹 Batch Loss: {loss.item()}\")\n",
        "\n",
        "#         accuracy = correct / total if total > 0 else 0.0\n",
        "#         logging.info(f\"✅ Evaluation Results - Loss: {total_loss / len(self.test_loader):.4f}, Accuracy: {accuracy:.2%}\")\n",
        "#         return total_loss / len(self.test_loader), len(self.test_loader.dataset), {\"accuracy\": accuracy}\n",
        "\n",
        "# # ✅ Custom Strategy for Evaluation Debugging\n",
        "# class PrintEvaluateStrategy(fl.server.strategy.FedAvg):\n",
        "#     def aggregate_evaluate(self, rnd: int, results, failures):\n",
        "#         aggregated = super().aggregate_evaluate(rnd, results, failures)\n",
        "#         if aggregated is None:\n",
        "#             logging.info(f\"[ROUND {rnd}] No evaluation results\")\n",
        "#             return aggregated\n",
        "#         if isinstance(aggregated, tuple):\n",
        "#             if len(aggregated) == 3:\n",
        "#                 loss, num_examples, metrics = aggregated\n",
        "#             elif len(aggregated) == 2:\n",
        "#                 loss, num_examples = aggregated\n",
        "#                 num_examples = num_examples if isinstance(num_examples, int) else \"unknown\"\n",
        "#                 metrics = {}\n",
        "#             else:\n",
        "#                 loss, num_examples, metrics = aggregated, \"unknown\", {}\n",
        "#         else:\n",
        "#             logging.info(f\"[ROUND {rnd}] Aggregated evaluation: {aggregated}\")\n",
        "#             return aggregated\n",
        "\n",
        "#         accuracy = metrics.get(\"accuracy\", None)\n",
        "#         accuracy_str = f\"{accuracy:.2%}\" if accuracy is not None else \"N/A\"\n",
        "#         logging.info(f\"[ROUND {rnd}] Evaluation results: Loss: {loss:.4f}, Accuracy: {accuracy_str} on {num_examples} examples\")\n",
        "#         return aggregated\n",
        "\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "# strategy = PrintEvaluateStrategy(min_fit_clients=4, min_available_clients=4)\n",
        "\n",
        "# for features, labels in train_loader:\n",
        "#     print(f\"Feature shape: {features.shape}, Label shape: {labels.shape}\")\n",
        "#     break  # Only check first batch\n",
        "\n",
        "\n",
        "# fl.simulation.start_simulation(\n",
        "#     client_fn=lambda ctx: FLClient(model, train_loader, test_loader),\n",
        "#     num_clients=4,\n",
        "#     config=fl.server.ServerConfig(num_rounds=2),\n",
        "#     strategy=fl.server.strategy.FedAvg(),\n",
        "#     ray_init_args={\n",
        "#         \"num_cpus\": 4,  # ✅ Only use CPU\n",
        "#         \"include_dashboard\": False,\n",
        "#         \"ignore_reinit_error\": True,\n",
        "#     },\n",
        "#     client_resources={\"num_cpus\": 1}  # ✅ No GPU needed\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OqvpYJzfAG_0"
      },
      "outputs": [],
      "source": [
        "# import logging\n",
        "# import time\n",
        "# import flwr as fl\n",
        "\n",
        "# import importlib\n",
        "# import ray\n",
        "# importlib.reload(ray)\n",
        "\n",
        "# from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import librosa\n",
        "# import numpy as np\n",
        "# import random\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from speechbrain.pretrained import EncoderClassifier\n",
        "# from torch.optim import Adam\n",
        "# from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "# from scipy.stats import mode\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# # **Set device**\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # **Load Pretrained Speaker Encoder (ECAPA-TDNN)**\n",
        "# speaker_encoder = EncoderClassifier.from_hparams(\n",
        "#     source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "#     savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "#     run_opts={\"device\": device}\n",
        "# ).to(device)\n",
        "\n",
        "# # **Freeze the speaker encoder**\n",
        "# for param in speaker_encoder.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# # **Function to extract speaker embeddings**\n",
        "# def extract_speaker_embedding(features):\n",
        "#     \"\"\"Extracts speaker embeddings using ECAPA-TDNN.\"\"\"\n",
        "#     with torch.no_grad():\n",
        "#         embeddings = speaker_encoder.encode_batch(features)\n",
        "#         return embeddings.squeeze(1)  # Remove unnecessary dimension\n",
        "\n",
        "# # **Power-Set Encoding Function**\n",
        "# def power_set_encoding(labels):\n",
        "#     \"\"\"Encodes multi-label speaker activation into a single integer using power-set encoding.\"\"\"\n",
        "#     return sum([l * (2 ** i) for i, l in enumerate(labels) if l in [0, 1]])\n",
        "\n",
        "# # **Overlapping Speech Simulation**\n",
        "# def simulate_overlap(grouped_data, num_speakers=2, duration=10, sampling_rate=16000):\n",
        "#     overlapping_segments = []\n",
        "#     labels = []\n",
        "#     for meeting_id, samples in grouped_data.items():\n",
        "#         speakers = {sample[\"speaker_id\"]: [] for sample in samples}\n",
        "#         for sample in samples:\n",
        "#             speakers[sample[\"speaker_id\"]].append(sample)\n",
        "#         if len(speakers) < num_speakers:\n",
        "#             continue\n",
        "#         for _ in range(50):\n",
        "#             chosen_speakers = random.sample(list(speakers.keys()), num_speakers)\n",
        "#             combined_signal = None\n",
        "#             speaker_label = [0] * len(speakers)\n",
        "#             for speaker_id in chosen_speakers:\n",
        "#                 sample = random.choice(speakers[speaker_id])\n",
        "#                 signal = sample[\"audio\"][\"array\"]\n",
        "#                 if len(signal) > duration * sampling_rate:\n",
        "#                     signal = signal[: duration * sampling_rate]\n",
        "#                 else:\n",
        "#                     signal = np.pad(signal, (0, duration * sampling_rate - len(signal)), mode=\"constant\")\n",
        "#                 if combined_signal is None:\n",
        "#                     combined_signal = signal\n",
        "#                 else:\n",
        "#                     combined_signal += signal\n",
        "#                 speaker_label[list(speakers.keys()).index(speaker_id)] = 1\n",
        "#             if combined_signal is not None and np.max(np.abs(combined_signal)) > 0:\n",
        "#                 combined_signal = combined_signal / np.max(np.abs(combined_signal))\n",
        "#             else:\n",
        "#                 continue\n",
        "#             overlapping_segments.append(combined_signal)\n",
        "#             labels.append(power_set_encoding(speaker_label))\n",
        "\n",
        "#     # ✅ Debug: Print the first few labels to check if overlapping speech is simulated correctly\n",
        "#     print(\"🔹 Sample labels from train set (Power-Set Encoded):\")\n",
        "#     for i in range(min(10, len(labels))):  # Print up to 10 samples\n",
        "#         print(labels[i])\n",
        "\n",
        "#     return overlapping_segments, labels\n",
        "\n",
        "\n",
        "# # **Feature Extraction (Log-Mel Spectrograms)**\n",
        "# def extract_features_batch(segments, sr=16000, n_mels=80, win_length=0.025, hop_length=0.01, max_frames=None):\n",
        "#     features = []\n",
        "#     win_length_samples = int(win_length * sr)\n",
        "#     hop_length_samples = int(hop_length * sr)\n",
        "\n",
        "#     for segment in segments:\n",
        "#         mel_spec = librosa.feature.melspectrogram(\n",
        "#             y=segment, sr=sr, n_mels=n_mels, win_length=win_length_samples, hop_length=hop_length_samples\n",
        "#         )\n",
        "#         log_mel = librosa.power_to_db(mel_spec)\n",
        "\n",
        "#         if max_frames:\n",
        "#             log_mel = log_mel[:, :max_frames] if log_mel.shape[1] > max_frames else np.pad(\n",
        "#                 log_mel, ((0, 0), (0, max_frames - log_mel.shape[1])), mode=\"constant\"\n",
        "#             )\n",
        "\n",
        "#         features.append(log_mel.T)\n",
        "\n",
        "#     features = np.array(features, dtype=np.float32)\n",
        "\n",
        "#     return torch.tensor(features, dtype=torch.float32)  # ✅ Corrected tensor conversion\n",
        "\n",
        "# class OverlappingSpeechDataset(Dataset):\n",
        "#     def __init__(self, features, labels):\n",
        "#         self.features = features\n",
        "#         self.labels = labels\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.features)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "#         label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "#         return feature, label\n",
        "\n",
        "# scaler = torch.cuda.amp.GradScaler()  # ✅ Mixed Precision Scaling\n",
        "\n",
        "# # **Training Execution**\n",
        "# num_speakers = 5\n",
        "\n",
        "# # Simulate overlapping speech for training\n",
        "# train_segments, train_labels = simulate_overlap(grouped_train)\n",
        "# val_segments, val_labels = simulate_overlap(grouped_validation)\n",
        "# test_segments, test_labels = simulate_overlap(grouped_test)\n",
        "\n",
        "# from collections import Counter\n",
        "\n",
        "# print(\"🔹 Unique Labels in Training Set:\", set(train_labels))\n",
        "# print(\"🔹 Label Distribution:\")\n",
        "# label_counts = Counter(train_labels)\n",
        "# for label, count in label_counts.items():\n",
        "#     binary_repr = bin(label)[2:].zfill(num_speakers)  # Convert to binary\n",
        "#     print(f\"Label: {label}, Binary: {binary_repr}, Count: {count}\")\n",
        "\n",
        "# unique_labels = sorted(set(train_labels + val_labels))  # ✅ Include val_labels\n",
        "# label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "# index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
        "\n",
        "# print(f\"🔹 Label Mapping: {label_to_index}\")\n",
        "\n",
        "# num_classes = len(unique_labels)  # ✅ Actual number of classes\n",
        "\n",
        "# # Apply mapping to training and validation labels\n",
        "# train_labels = [label_to_index[label] for label in train_labels]\n",
        "# val_labels = [label_to_index[label] for label in val_labels]\n",
        "\n",
        "# print(f\"🔹 Mapped Training Labels: {train_labels[:10]}\")  # Debugging\n",
        "\n",
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# def collate_fn_pad(batch):\n",
        "#     \"\"\"Pads variable-length sequences to the longest in the batch, ensuring consistent batch shapes.\"\"\"\n",
        "#     batch = [b for b in batch if b is not None]  # Remove None samples\n",
        "\n",
        "#     if len(batch) == 0:\n",
        "#         return None, None  # Return empty batch if all are invalid\n",
        "\n",
        "#     features, labels = zip(*batch)\n",
        "\n",
        "#     # ✅ Pad sequences to the maximum length in this batch\n",
        "#     features_padded = pad_sequence(features, batch_first=True, padding_value=0)\n",
        "\n",
        "#     # ✅ Keep labels as scalars (no expansion)\n",
        "#     labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "#     return features_padded, labels\n",
        "\n",
        "\n",
        "# max_frames = int((10 / 0.01))  # 10s duration, 0.01 hop length (10s / 10ms)\n",
        "# train_features = extract_features_batch(train_segments, max_frames=max_frames)\n",
        "# val_features = extract_features_batch(val_segments, max_frames=max_frames)\n",
        "# test_features = extract_features_batch(test_segments, max_frames=max_frames)\n",
        "\n",
        "# train_loader = DataLoader(\n",
        "#     OverlappingSpeechDataset(train_features, train_labels),\n",
        "#     batch_size=16,\n",
        "#     shuffle=True,\n",
        "#     collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        "# )\n",
        "\n",
        "# val_loader = DataLoader(\n",
        "#     OverlappingSpeechDataset(val_features, val_labels),\n",
        "#     batch_size=16,\n",
        "#     shuffle=False,\n",
        "#     collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        "# )\n",
        "\n",
        "# test_loader = DataLoader(\n",
        "#     OverlappingSpeechDataset(test_features, test_labels),\n",
        "#     batch_size=16,\n",
        "#     shuffle=False,\n",
        "#     collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        "# )\n",
        "\n",
        "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # ✅ Define `speaker_encoder` correctly\n",
        "# speaker_encoder = EncoderClassifier.from_hparams(\n",
        "#     source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "#     savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "#     run_opts={\"device\": DEVICE}\n",
        "# ).to(DEVICE)\n",
        "\n",
        "# # **SEND Model**\n",
        "# class SpeechEncoder(nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim, num_layers):\n",
        "#         super().__init__()\n",
        "#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x, _ = self.lstm(x)\n",
        "#         return x\n",
        "\n",
        "# class SEND(nn.Module):\n",
        "#     def __init__(self, input_dim, speaker_dim, hidden_dim, num_layers, num_speakers):\n",
        "#         super().__init__()\n",
        "#         self.speech_encoder = SpeechEncoder(input_dim, hidden_dim, num_layers)\n",
        "#         self.speaker_encoder = speaker_encoder.encode_batch\n",
        "\n",
        "#         self.feature_projection = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n",
        "#         self.context_independent = nn.Linear(hidden_dim * 2, num_speakers)\n",
        "#         self.context_dependent = nn.TransformerEncoder(nn.TransformerEncoderLayer(hidden_dim * 2, 4), num_layers)\n",
        "#         self.match_projection = nn.Linear(hidden_dim * 2, num_speakers)\n",
        "#         self.post_net = nn.Linear(hidden_dim * 2, 2 ** num_speakers)  # Ensure input matches hidden_dim * 2\n",
        "\n",
        "#     def forward(self, speech):\n",
        "#         # Ensure correct shape\n",
        "#         if speech.dim() == 4:\n",
        "#             speech = speech.squeeze(1)\n",
        "\n",
        "#         speech_features = self.speech_encoder(speech)\n",
        "#         # print(f\"🔹 Speech features shape after LSTM: {speech_features.shape}\")  # [16, 29, 512]\n",
        "\n",
        "#         speech_features = self.feature_projection(speech_features)\n",
        "#         # print(f\"🔹 Projected speech features shape: {speech_features.shape}\")  # [16, 29, 512]\n",
        "\n",
        "#         # **Apply mean pooling across time dimension (sequence length 29)**\n",
        "#         pooled_features = torch.mean(speech_features, dim=1)  # [16, 512]\n",
        "#         # print(f\"🔹 Pooled features shape: {pooled_features.shape}\")  # [16, 512]\n",
        "\n",
        "#         # Ensure output matches batch size\n",
        "#         output = self.post_net(pooled_features)  # [16, num_classes]\n",
        "#         # print(f\"🔹 Model output shape: {output.shape}\")  # Should be [16, 2**num_speakers]\n",
        "\n",
        "#         return output\n",
        "\n",
        "# model = SEND(input_dim=80, speaker_dim=512, hidden_dim=256, num_layers=4, num_speakers=num_speakers).to(DEVICE)\n",
        "\n",
        "# from pyannote.core import Annotation, Segment\n",
        "# from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "\n",
        "# def compute_der(predictions, ground_truths, timestamps):\n",
        "#     metric = DiarizationErrorRate()\n",
        "#     pred_annotation = Annotation()\n",
        "#     gt_annotation = Annotation()\n",
        "\n",
        "#     for i, (start, end) in enumerate(timestamps):\n",
        "#         pred_annotation[Segment(start, end)] = str(predictions[i])\n",
        "#         gt_annotation[Segment(start, end)] = str(ground_truths[i])\n",
        "\n",
        "#     der_score = metric(gt_annotation, pred_annotation)\n",
        "#     logging.info(f\"🔹 DER Computed: {der_score:.4f}\")\n",
        "#     return der_score\n",
        "\n",
        "# def labels_to_annotation(labels, num_speakers, frame_duration=0.01):\n",
        "#     annotation = Annotation()\n",
        "\n",
        "#     if isinstance(labels, (np.ndarray, torch.Tensor)):\n",
        "#         labels = labels.flatten().tolist()  # Convert tensor to list\n",
        "\n",
        "#     label = int(mode(labels, keepdims=True)[0][0])  # ✅ Fixed mode extraction\n",
        "#     print(f\"🔹 Decoded Label: {label}\")\n",
        "\n",
        "#     active_speakers = [bool(label & (1 << i)) for i in range(num_speakers)]\n",
        "\n",
        "#     if isinstance(labels, (list, np.ndarray, torch.Tensor)):\n",
        "#         end_time = len(labels) * frame_duration\n",
        "#     else:\n",
        "#         end_time = frame_duration  # Single label case\n",
        "\n",
        "#     start_time = 0\n",
        "#     for speaker_idx, is_active in enumerate(active_speakers):\n",
        "#         if is_active:\n",
        "#             annotation[Segment(start_time, end_time)] = f\"Speaker_{speaker_idx}\"\n",
        "\n",
        "#     print(f\"Decoded label: {label}, Active speakers: {active_speakers}\")\n",
        "\n",
        "#     return annotation\n",
        "\n",
        "# def calculate_der(model, test_loader, num_speakers):\n",
        "#     der_metric = DiarizationErrorRate()\n",
        "#     total_der = 0\n",
        "#     num_samples = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for i, (features, labels) in enumerate(test_loader):\n",
        "#             features = features.to(device)\n",
        "#             outputs = model(features)\n",
        "#             predicted_labels = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
        "#             labels = labels.cpu().numpy()\n",
        "\n",
        "#             for j in range(len(labels)):\n",
        "#                 ref_annotation = labels_to_annotation(labels[j], num_speakers)\n",
        "#                 hyp_annotation = labels_to_annotation(predicted_labels[j], num_speakers)\n",
        "\n",
        "#                 der = der_metric(ref_annotation, hyp_annotation)\n",
        "\n",
        "#                 logging.info(f\"🔹 Sample {i}-{j} | DER: {der:.2%}\")\n",
        "\n",
        "#                 total_der += der\n",
        "#                 num_samples += 1\n",
        "\n",
        "#     avg_der = total_der / num_samples if num_samples > 0 else 0\n",
        "#     logging.info(f\"\\n✅ Final Validation DER: {avg_der:.2%}\")\n",
        "#     return avg_der\n",
        "\n",
        "\n",
        "# class FLClient(NumPyClient):\n",
        "#     def __init__(self, model, train_loader, test_loader):\n",
        "#         os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # ✅ Force CPU globally\n",
        "#         self.device = torch.device(\"cpu\")  # ✅ Force CPU for PyTorch\n",
        "#         logging.info(f\"Using device: {self.device}\")\n",
        "#         self.model = model.to(self.device)  # ✅ Move model to CPU\n",
        "#         self.train_loader = train_loader\n",
        "#         self.test_loader = test_loader\n",
        "#         self.optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "#         self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#     def get_parameters(self, config=None):\n",
        "#         return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "#     def set_parameters(self, parameters):\n",
        "#         state_dict = {k: torch.tensor(v).to(self.device) for k, v in zip(self.model.state_dict().keys(), parameters)}\n",
        "#         self.model.load_state_dict(state_dict)\n",
        "#         self.model.to(self.device)  # Ensure model is on the right device\n",
        "\n",
        "#     def fit(self, parameters, config):\n",
        "#         self.set_parameters(parameters)\n",
        "#         self.model.train()\n",
        "\n",
        "#         logging.info(f\"Training on {self.device}...\")\n",
        "\n",
        "#         # 🔹 Check initial weights before training\n",
        "#         initial_weight = self.model.speech_encoder.lstm.weight_ih_l0.clone().detach().cpu()\n",
        "\n",
        "#         total_loss = 0\n",
        "#         for epoch in range(2):\n",
        "#             for batch_idx, (features, labels) in enumerate(self.train_loader):\n",
        "#                 features, labels = features.to(self.device), labels.to(self.device)\n",
        "\n",
        "#                 logging.info(f\"Batch {batch_idx} \")\n",
        "#                 logging.info(f\"Sample labels: {labels[:5]}\")\n",
        "\n",
        "#                 self.optimizer.zero_grad()\n",
        "#                 outputs = self.model(features)\n",
        "\n",
        "#                 preds = torch.argmax(outputs, dim=-1).cpu().tolist()  # 🔹 Get predictions\n",
        "\n",
        "#                 labels = labels.view(-1)\n",
        "#                 loss = self.criterion(outputs, labels.long())\n",
        "#                 loss.backward()\n",
        "#                 self.optimizer.step()\n",
        "\n",
        "#                 total_loss += loss.item()\n",
        "\n",
        "#                 # 🔹 Check if predictions vary across batches\n",
        "#                 logging.info(f\"🔹 Predictions (Batch {batch_idx}): {preds[:5]}\")\n",
        "#                 logging.info(f\"🔹 Ground Truth: {labels[:5].tolist()}\")\n",
        "\n",
        "\n",
        "\n",
        "#         avg_loss = total_loss / len(self.train_loader)\n",
        "\n",
        "#         # 🔹 Check if weights changed after training\n",
        "#         updated_weight = self.model.speech_encoder.lstm.weight_ih_l0.clone().detach().cpu()\n",
        "#         weight_change = torch.sum((updated_weight - initial_weight) ** 2).item()\n",
        "\n",
        "#         logging.info(f\"✅ Training completed. Avg Loss: {avg_loss:.4f}, Weight Change: {weight_change:.6f}\")\n",
        "\n",
        "#         return self.get_parameters(), len(self.train_loader.dataset), {\"loss\": avg_loss, \"weight_change\": weight_change}\n",
        "\n",
        "#     def evaluate(self, parameters, config):\n",
        "#         self.set_parameters(parameters)  # Load the latest model parameters\n",
        "#         self.model.eval()\n",
        "\n",
        "#         logging.info(f\"🔹 Evaluating Model on {self.device}...\")\n",
        "\n",
        "#         avg_der = calculate_der(self.model, self.test_loader, num_speakers)\n",
        "\n",
        "#         logging.info(f\"✅ Evaluation Results - DER: {avg_der:.2%}\")\n",
        "\n",
        "#         return 0.0, len(self.test_loader.dataset), {\"der\": avg_der}\n",
        "\n",
        "\n",
        "# # ✅ Custom Strategy for Evaluation Debugging\n",
        "# class PrintEvaluateStrategy(fl.server.strategy.FedAvg):\n",
        "#     def aggregate_evaluate(self, rnd: int, results, failures):\n",
        "#         aggregated = super().aggregate_evaluate(rnd, results, failures)\n",
        "#         if aggregated is None:\n",
        "#             logging.info(f\"[ROUND {rnd}] No evaluation results\")\n",
        "#             return aggregated\n",
        "#         if isinstance(aggregated, tuple):\n",
        "#             if len(aggregated) == 3:\n",
        "#                 loss, num_examples, metrics = aggregated\n",
        "#             elif len(aggregated) == 2:\n",
        "#                 loss, num_examples = aggregated\n",
        "#                 num_examples = num_examples if isinstance(num_examples, int) else \"unknown\"\n",
        "#                 metrics = {}\n",
        "#             else:\n",
        "#                 loss, num_examples, metrics = aggregated, \"unknown\", {}\n",
        "#         else:\n",
        "#             logging.info(f\"[ROUND {rnd}] Aggregated evaluation: {aggregated}\")\n",
        "#             return aggregated\n",
        "\n",
        "#         accuracy = metrics.get(\"accuracy\", None)\n",
        "#         accuracy_str = f\"{accuracy:.2%}\" if accuracy is not None else \"N/A\"\n",
        "#         logging.info(f\"[ROUND {rnd}] Evaluation results: Loss: {loss:.4f}, Accuracy: {accuracy_str} on {num_examples} examples\")\n",
        "#         return aggregated\n",
        "\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "# strategy = PrintEvaluateStrategy(min_fit_clients=4, min_available_clients=4)\n",
        "\n",
        "# for features, labels in train_loader:\n",
        "#     print(f\"Feature shape: {features.shape}, Label shape: {labels.shape}\")\n",
        "#     break  # Only check first batch\n",
        "\n",
        "\n",
        "# fl.simulation.start_simulation(\n",
        "#     client_fn=lambda ctx: FLClient(model, train_loader, test_loader),\n",
        "#     num_clients=4,\n",
        "#     config=fl.server.ServerConfig(num_rounds=2),\n",
        "#     strategy=fl.server.strategy.FedAvg(),\n",
        "#     ray_init_args={\n",
        "#         \"num_cpus\": 4,  # ✅ Only use CPU\n",
        "#         \"include_dashboard\": False,\n",
        "#         \"ignore_reinit_error\": True,\n",
        "#     },\n",
        "#     client_resources={\"num_cpus\": 1}  # ✅ No GPU needed\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twladvQGLQ-6"
      },
      "source": [
        "## batch=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OFLwZmxBKvFT"
      },
      "outputs": [],
      "source": [
        "# import logging\n",
        "# import time\n",
        "# import flwr as fl\n",
        "\n",
        "# import importlib\n",
        "# import ray\n",
        "# importlib.reload(ray)\n",
        "\n",
        "# from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import librosa\n",
        "# import numpy as np\n",
        "# import random\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from speechbrain.pretrained import EncoderClassifier\n",
        "# from torch.optim import Adam\n",
        "# from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "# from scipy.stats import mode\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# # **Set device**\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # **Load Pretrained Speaker Encoder (ECAPA-TDNN)**\n",
        "# speaker_encoder = EncoderClassifier.from_hparams(\n",
        "#     source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "#     savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "#     run_opts={\"device\": device}\n",
        "# ).to(device)\n",
        "\n",
        "# # **Freeze the speaker encoder**\n",
        "# for param in speaker_encoder.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# # **Function to extract speaker embeddings**\n",
        "# def extract_speaker_embedding(features):\n",
        "#     \"\"\"Extracts speaker embeddings using ECAPA-TDNN.\"\"\"\n",
        "#     with torch.no_grad():\n",
        "#         embeddings = speaker_encoder.encode_batch(features)\n",
        "#         return embeddings.squeeze(1)  # Remove unnecessary dimension\n",
        "\n",
        "# # **Power-Set Encoding Function**\n",
        "# def power_set_encoding(labels):\n",
        "#     \"\"\"Encodes multi-label speaker activation into a single integer using power-set encoding.\"\"\"\n",
        "#     return sum([l * (2 ** i) for i, l in enumerate(labels) if l in [0, 1]])\n",
        "\n",
        "# # **Overlapping Speech Simulation**\n",
        "# def simulate_overlap(grouped_data, num_speakers=2, duration=10, sampling_rate=16000):\n",
        "#     overlapping_segments = []\n",
        "#     labels = []\n",
        "#     for meeting_id, samples in grouped_data.items():\n",
        "#         speakers = {sample[\"speaker_id\"]: [] for sample in samples}\n",
        "#         for sample in samples:\n",
        "#             speakers[sample[\"speaker_id\"]].append(sample)\n",
        "#         if len(speakers) < num_speakers:\n",
        "#             continue\n",
        "#         for _ in range(50):\n",
        "#             chosen_speakers = random.sample(list(speakers.keys()), num_speakers)\n",
        "#             combined_signal = None\n",
        "#             speaker_label = [0] * len(speakers)\n",
        "#             for speaker_id in chosen_speakers:\n",
        "#                 sample = random.choice(speakers[speaker_id])\n",
        "#                 signal = sample[\"audio\"][\"array\"]\n",
        "#                 if len(signal) > duration * sampling_rate:\n",
        "#                     signal = signal[: duration * sampling_rate]\n",
        "#                 else:\n",
        "#                     signal = np.pad(signal, (0, duration * sampling_rate - len(signal)), mode=\"constant\")\n",
        "#                 if combined_signal is None:\n",
        "#                     combined_signal = signal\n",
        "#                 else:\n",
        "#                     combined_signal += signal\n",
        "#                 speaker_label[list(speakers.keys()).index(speaker_id)] = 1\n",
        "#             if combined_signal is not None and np.max(np.abs(combined_signal)) > 0:\n",
        "#                 combined_signal = combined_signal / np.max(np.abs(combined_signal))\n",
        "#             else:\n",
        "#                 continue\n",
        "#             overlapping_segments.append(combined_signal)\n",
        "#             labels.append(power_set_encoding(speaker_label))\n",
        "\n",
        "#     # ✅ Debug: Print the first few labels to check if overlapping speech is simulated correctly\n",
        "#     print(\"🔹 Sample labels from train set (Power-Set Encoded):\")\n",
        "#     for i in range(min(10, len(labels))):  # Print up to 10 samples\n",
        "#         print(labels[i])\n",
        "\n",
        "#     return overlapping_segments, labels\n",
        "\n",
        "\n",
        "# # **Feature Extraction (Log-Mel Spectrograms)**\n",
        "# def extract_features_batch(segments, sr=16000, n_mels=80, win_length=0.025, hop_length=0.01, max_frames=None):\n",
        "#     features = []\n",
        "#     win_length_samples = int(win_length * sr)\n",
        "#     hop_length_samples = int(hop_length * sr)\n",
        "\n",
        "#     for segment in segments:\n",
        "#         mel_spec = librosa.feature.melspectrogram(\n",
        "#             y=segment, sr=sr, n_mels=n_mels, win_length=win_length_samples, hop_length=hop_length_samples\n",
        "#         )\n",
        "#         log_mel = librosa.power_to_db(mel_spec)\n",
        "\n",
        "#         if max_frames:\n",
        "#             log_mel = log_mel[:, :max_frames] if log_mel.shape[1] > max_frames else np.pad(\n",
        "#                 log_mel, ((0, 0), (0, max_frames - log_mel.shape[1])), mode=\"constant\"\n",
        "#             )\n",
        "\n",
        "#         features.append(log_mel.T)\n",
        "\n",
        "#     features = np.array(features, dtype=np.float32)\n",
        "\n",
        "#     return torch.tensor(features, dtype=torch.float32)  # ✅ Corrected tensor conversion\n",
        "\n",
        "# class OverlappingSpeechDataset(Dataset):\n",
        "#     def __init__(self, features, labels):\n",
        "#         self.features = features\n",
        "#         self.labels = labels\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.features)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "#         label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "#         return feature, label\n",
        "\n",
        "# scaler = torch.cuda.amp.GradScaler()  # ✅ Mixed Precision Scaling\n",
        "\n",
        "# # **Training Execution**\n",
        "# num_speakers = 5\n",
        "\n",
        "# # Simulate overlapping speech for training\n",
        "# train_segments, train_labels = simulate_overlap(grouped_train)\n",
        "# val_segments, val_labels = simulate_overlap(grouped_validation)\n",
        "# test_segments, test_labels = simulate_overlap(grouped_test)\n",
        "\n",
        "# from collections import Counter\n",
        "\n",
        "# print(\"🔹 Unique Labels in Training Set:\", set(train_labels))\n",
        "# print(\"🔹 Label Distribution:\")\n",
        "# label_counts = Counter(train_labels)\n",
        "# for label, count in label_counts.items():\n",
        "#     binary_repr = bin(label)[2:].zfill(num_speakers)  # Convert to binary\n",
        "#     print(f\"Label: {label}, Binary: {binary_repr}, Count: {count}\")\n",
        "\n",
        "# unique_labels = sorted(set(train_labels + val_labels))  # ✅ Include val_labels\n",
        "# label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "# index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
        "\n",
        "# print(f\"🔹 Label Mapping: {label_to_index}\")\n",
        "\n",
        "# num_classes = len(unique_labels)  # ✅ Actual number of classes\n",
        "\n",
        "# # Apply mapping to training and validation labels\n",
        "# train_labels = [label_to_index[label] for label in train_labels]\n",
        "# val_labels = [label_to_index[label] for label in val_labels]\n",
        "\n",
        "# print(f\"🔹 Mapped Training Labels: {train_labels[:10]}\")  # Debugging\n",
        "\n",
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# def collate_fn_pad(batch):\n",
        "#     \"\"\"Pads variable-length sequences to the longest in the batch, ensuring consistent batch shapes.\"\"\"\n",
        "#     batch = [b for b in batch if b is not None]  # Remove None samples\n",
        "\n",
        "#     if len(batch) == 0:\n",
        "#         return None, None  # Return empty batch if all are invalid\n",
        "\n",
        "#     features, labels = zip(*batch)\n",
        "\n",
        "#     # ✅ Pad sequences to the maximum length in this batch\n",
        "#     features_padded = pad_sequence(features, batch_first=True, padding_value=0)\n",
        "\n",
        "#     # ✅ Keep labels as scalars (no expansion)\n",
        "#     labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "#     return features_padded, labels\n",
        "\n",
        "\n",
        "# max_frames = int((10 / 0.01))  # 10s duration, 0.01 hop length (10s / 10ms)\n",
        "# train_features = extract_features_batch(train_segments, max_frames=max_frames)\n",
        "# val_features = extract_features_batch(val_segments, max_frames=max_frames)\n",
        "# test_features = extract_features_batch(test_segments, max_frames=max_frames)\n",
        "\n",
        "# train_loader = DataLoader(\n",
        "#     OverlappingSpeechDataset(train_features, train_labels),\n",
        "#     batch_size=1,\n",
        "#     shuffle=True,\n",
        "#     collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        "# )\n",
        "\n",
        "# val_loader = DataLoader(\n",
        "#     OverlappingSpeechDataset(val_features, val_labels),\n",
        "#     batch_size=1,\n",
        "#     shuffle=False,\n",
        "#     collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        "# )\n",
        "\n",
        "# test_loader = DataLoader(\n",
        "#     OverlappingSpeechDataset(test_features, test_labels),\n",
        "#     batch_size=1,\n",
        "#     shuffle=False,\n",
        "#     collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        "# )\n",
        "\n",
        "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # ✅ Define `speaker_encoder` correctly\n",
        "# speaker_encoder = EncoderClassifier.from_hparams(\n",
        "#     source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "#     savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "#     run_opts={\"device\": DEVICE}\n",
        "# ).to(DEVICE)\n",
        "\n",
        "# # **SEND Model**\n",
        "# class SpeechEncoder(nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim, num_layers):\n",
        "#         super().__init__()\n",
        "#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x, _ = self.lstm(x)\n",
        "#         return x\n",
        "\n",
        "# class SEND(nn.Module):\n",
        "#     def __init__(self, input_dim, speaker_dim, hidden_dim, num_layers, num_speakers):\n",
        "#         super().__init__()\n",
        "#         self.speech_encoder = SpeechEncoder(input_dim, hidden_dim, num_layers)\n",
        "#         self.speaker_encoder = speaker_encoder.encode_batch\n",
        "\n",
        "#         self.feature_projection = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n",
        "#         self.context_independent = nn.Linear(hidden_dim * 2, num_speakers)\n",
        "#         self.context_dependent = nn.TransformerEncoder(nn.TransformerEncoderLayer(hidden_dim * 2, 4), num_layers)\n",
        "#         self.match_projection = nn.Linear(hidden_dim * 2, num_speakers)\n",
        "#         self.post_net = nn.Linear(hidden_dim * 2, 2 ** num_speakers)  # Ensure input matches hidden_dim * 2\n",
        "\n",
        "#     def forward(self, speech):\n",
        "#         # Ensure correct shape\n",
        "#         if speech.dim() == 4:\n",
        "#             speech = speech.squeeze(1)\n",
        "\n",
        "#         speech_features = self.speech_encoder(speech)\n",
        "#         # print(f\"🔹 Speech features shape after LSTM: {speech_features.shape}\")  # [16, 29, 512]\n",
        "\n",
        "#         speech_features = self.feature_projection(speech_features)\n",
        "#         # print(f\"🔹 Projected speech features shape: {speech_features.shape}\")  # [16, 29, 512]\n",
        "\n",
        "#         # **Apply mean pooling across time dimension (sequence length 29)**\n",
        "#         pooled_features = torch.mean(speech_features, dim=1)  # [16, 512]\n",
        "#         # print(f\"🔹 Pooled features shape: {pooled_features.shape}\")  # [16, 512]\n",
        "\n",
        "#         # Ensure output matches batch size\n",
        "#         output = self.post_net(pooled_features)  # [16, num_classes]\n",
        "#         # print(f\"🔹 Model output shape: {output.shape}\")  # Should be [16, 2**num_speakers]\n",
        "\n",
        "#         return output\n",
        "\n",
        "# model = SEND(input_dim=80, speaker_dim=512, hidden_dim=256, num_layers=4, num_speakers=num_speakers).to(DEVICE)\n",
        "\n",
        "# from pyannote.core import Annotation, Segment\n",
        "# from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "\n",
        "# def compute_der(predictions, ground_truths, timestamps):\n",
        "#     metric = DiarizationErrorRate()\n",
        "#     pred_annotation = Annotation()\n",
        "#     gt_annotation = Annotation()\n",
        "\n",
        "#     for i, (start, end) in enumerate(timestamps):\n",
        "#         pred_annotation[Segment(start, end)] = str(predictions[i])\n",
        "#         gt_annotation[Segment(start, end)] = str(ground_truths[i])\n",
        "\n",
        "#     der_score = metric(gt_annotation, pred_annotation)\n",
        "#     logging.info(f\"🔹 DER Computed: {der_score:.4f}\")\n",
        "#     return der_score\n",
        "\n",
        "# def labels_to_annotation(labels, num_speakers, frame_duration=0.01):\n",
        "#     annotation = Annotation()\n",
        "\n",
        "#     if isinstance(labels, (np.ndarray, torch.Tensor)):\n",
        "#         labels = labels.flatten().tolist()  # Convert tensor to list\n",
        "\n",
        "#     label = int(mode(labels, keepdims=True)[0][0])  # ✅ Fixed mode extraction\n",
        "#     print(f\"🔹 Decoded Label: {label}\")\n",
        "\n",
        "#     active_speakers = [bool(label & (1 << i)) for i in range(num_speakers)]\n",
        "\n",
        "#     if isinstance(labels, (list, np.ndarray, torch.Tensor)):\n",
        "#         end_time = len(labels) * frame_duration\n",
        "#     else:\n",
        "#         end_time = frame_duration  # Single label case\n",
        "\n",
        "#     start_time = 0\n",
        "#     for speaker_idx, is_active in enumerate(active_speakers):\n",
        "#         if is_active:\n",
        "#             annotation[Segment(start_time, end_time)] = f\"Speaker_{speaker_idx}\"\n",
        "\n",
        "#     print(f\"Decoded label: {label}, Active speakers: {active_speakers}\")\n",
        "\n",
        "#     return annotation\n",
        "\n",
        "# def calculate_der(model, test_loader, num_speakers):\n",
        "#     der_metric = DiarizationErrorRate()\n",
        "#     total_der = 0\n",
        "#     num_samples = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for i, (features, labels) in enumerate(test_loader):\n",
        "#             features = features.to(device)\n",
        "#             outputs = model(features)\n",
        "#             predicted_labels = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
        "#             labels = labels.cpu().numpy()\n",
        "\n",
        "#             for j in range(len(labels)):\n",
        "#                 ref_annotation = labels_to_annotation(labels[j], num_speakers)\n",
        "#                 hyp_annotation = labels_to_annotation(predicted_labels[j], num_speakers)\n",
        "\n",
        "#                 der = der_metric(ref_annotation, hyp_annotation)\n",
        "\n",
        "#                 logging.info(f\"🔹 Sample {i}-{j} | DER: {der:.2%}\")\n",
        "\n",
        "#                 total_der += der\n",
        "#                 num_samples += 1\n",
        "\n",
        "#     avg_der = total_der / num_samples if num_samples > 0 else 0\n",
        "#     logging.info(f\"\\n✅ Final Validation DER: {avg_der:.2%}\")\n",
        "#     return avg_der\n",
        "\n",
        "\n",
        "# class FLClient(NumPyClient):\n",
        "#     def __init__(self, model, train_loader, test_loader):\n",
        "#         os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # ✅ Force CPU globally\n",
        "#         self.device = torch.device(\"cpu\")  # ✅ Force CPU for PyTorch\n",
        "#         logging.info(f\"Using device: {self.device}\")\n",
        "#         self.model = model.to(self.device)  # ✅ Move model to CPU\n",
        "#         self.train_loader = train_loader\n",
        "#         self.test_loader = test_loader\n",
        "#         self.optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "#         self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#     def get_parameters(self, config=None):\n",
        "#         return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "#     def set_parameters(self, parameters):\n",
        "#         state_dict = {k: torch.tensor(v).to(self.device) for k, v in zip(self.model.state_dict().keys(), parameters)}\n",
        "#         self.model.load_state_dict(state_dict)\n",
        "#         self.model.to(self.device)  # Ensure model is on the right device\n",
        "\n",
        "#     def fit(self, parameters, config):\n",
        "#         self.set_parameters(parameters)\n",
        "#         self.model.train()\n",
        "\n",
        "#         logging.info(f\"Training on {self.device}...\")\n",
        "\n",
        "#         # 🔹 Check initial weights before training\n",
        "#         initial_weight = self.model.speech_encoder.lstm.weight_ih_l0.clone().detach().cpu()\n",
        "\n",
        "#         total_loss = 0\n",
        "#         for epoch in range(2):\n",
        "#             for batch_idx, (features, labels) in enumerate(self.train_loader):\n",
        "#                 features, labels = features.to(self.device), labels.to(self.device)\n",
        "\n",
        "#                 logging.info(f\"Batch {batch_idx} \")\n",
        "#                 logging.info(f\"Sample labels: {labels[:5]}\")\n",
        "\n",
        "#                 self.optimizer.zero_grad()\n",
        "#                 outputs = self.model(features)\n",
        "\n",
        "#                 preds = torch.argmax(outputs, dim=-1).cpu().tolist()  # 🔹 Get predictions\n",
        "\n",
        "#                 labels = labels.view(-1)\n",
        "#                 loss = self.criterion(outputs, labels.long())\n",
        "#                 loss.backward()\n",
        "#                 self.optimizer.step()\n",
        "\n",
        "#                 total_loss += loss.item()\n",
        "\n",
        "#                 # 🔹 Check if predictions vary across batches\n",
        "#                 logging.info(f\"🔹 Predictions (Batch {batch_idx}): {preds[:5]}\")\n",
        "#                 logging.info(f\"🔹 Ground Truth: {labels[:5].tolist()}\")\n",
        "\n",
        "\n",
        "\n",
        "#         avg_loss = total_loss / len(self.train_loader)\n",
        "\n",
        "#         # 🔹 Check if weights changed after training\n",
        "#         updated_weight = self.model.speech_encoder.lstm.weight_ih_l0.clone().detach().cpu()\n",
        "#         weight_change = torch.sum((updated_weight - initial_weight) ** 2).item()\n",
        "\n",
        "#         logging.info(f\"✅ Training completed. Avg Loss: {avg_loss:.4f}, Weight Change: {weight_change:.6f}\")\n",
        "\n",
        "#         return self.get_parameters(), len(self.train_loader.dataset), {\"loss\": avg_loss, \"weight_change\": weight_change}\n",
        "\n",
        "#     def evaluate(self, parameters, config):\n",
        "#         self.set_parameters(parameters)  # Load the latest model parameters\n",
        "#         self.model.eval()\n",
        "\n",
        "#         logging.info(f\"🔹 Evaluating Model on {self.device}...\")\n",
        "\n",
        "#         avg_der = calculate_der(self.model, self.test_loader, num_speakers)\n",
        "\n",
        "#         logging.info(f\"✅ Evaluation Results - DER: {avg_der:.2%}\")\n",
        "\n",
        "#         return 0.0, len(self.test_loader.dataset), {\"der\": avg_der}\n",
        "\n",
        "\n",
        "# # ✅ Custom Strategy for Evaluation Debugging\n",
        "# class PrintEvaluateStrategy(fl.server.strategy.FedAvg):\n",
        "#     def aggregate_evaluate(self, rnd: int, results, failures):\n",
        "#         aggregated = super().aggregate_evaluate(rnd, results, failures)\n",
        "#         if aggregated is None:\n",
        "#             logging.info(f\"[ROUND {rnd}] No evaluation results\")\n",
        "#             return aggregated\n",
        "#         if isinstance(aggregated, tuple):\n",
        "#             if len(aggregated) == 3:\n",
        "#                 loss, num_examples, metrics = aggregated\n",
        "#             elif len(aggregated) == 2:\n",
        "#                 loss, num_examples = aggregated\n",
        "#                 num_examples = num_examples if isinstance(num_examples, int) else \"unknown\"\n",
        "#                 metrics = {}\n",
        "#             else:\n",
        "#                 loss, num_examples, metrics = aggregated, \"unknown\", {}\n",
        "#         else:\n",
        "#             logging.info(f\"[ROUND {rnd}] Aggregated evaluation: {aggregated}\")\n",
        "#             return aggregated\n",
        "\n",
        "#         accuracy = metrics.get(\"accuracy\", None)\n",
        "#         accuracy_str = f\"{accuracy:.2%}\" if accuracy is not None else \"N/A\"\n",
        "#         logging.info(f\"[ROUND {rnd}] Evaluation results: Loss: {loss:.4f}, Accuracy: {accuracy_str} on {num_examples} examples\")\n",
        "#         return aggregated\n",
        "\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "# strategy = PrintEvaluateStrategy(min_fit_clients=4, min_available_clients=4)\n",
        "\n",
        "# for features, labels in train_loader:\n",
        "#     print(f\"Feature shape: {features.shape}, Label shape: {labels.shape}\")\n",
        "#     break  # Only check first batch\n",
        "\n",
        "\n",
        "# fl.simulation.start_simulation(\n",
        "#     client_fn=lambda ctx: FLClient(model, train_loader, test_loader),\n",
        "#     num_clients=4,\n",
        "#     config=fl.server.ServerConfig(num_rounds=2),\n",
        "#     strategy=fl.server.strategy.FedAvg(),\n",
        "#     ray_init_args={\n",
        "#         \"num_cpus\": 4,  # ✅ Only use CPU\n",
        "#         \"include_dashboard\": False,\n",
        "#         \"ignore_reinit_error\": True,\n",
        "#     },\n",
        "#     client_resources={\"num_cpus\": 1}  # ✅ No GPU needed\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym-tjw_1Nqxd"
      },
      "source": [
        "## Batch = 1, fixing DER=0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import time\n",
        "import flwr as fl\n",
        "\n",
        "import importlib\n",
        "import ray\n",
        "importlib.reload(ray)\n",
        "\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import librosa\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "from torch.optim import Adam\n",
        "from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "from scipy.stats import mode\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# **Set device**\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# **Load Pretrained Speaker Encoder (ECAPA-TDNN)**\n",
        "speaker_encoder = EncoderClassifier.from_hparams(\n",
        "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "    run_opts={\"device\": device}\n",
        ").to(device)\n",
        "\n",
        "# **Freeze the speaker encoder**\n",
        "for param in speaker_encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# **Function to extract speaker embeddings**\n",
        "def extract_speaker_embedding(features):\n",
        "    \"\"\"Extracts speaker embeddings using ECAPA-TDNN.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        embeddings = speaker_encoder.encode_batch(features)\n",
        "        return embeddings.squeeze(1)  # Remove unnecessary dimension\n",
        "\n",
        "# **Power-Set Encoding Function**\n",
        "def power_set_encoding(labels):\n",
        "    \"\"\"Encodes multi-label speaker activation into a single integer using power-set encoding.\"\"\"\n",
        "    return sum([l * (2 ** i) for i, l in enumerate(labels) if l in [0, 1]])\n",
        "\n",
        "# **Overlapping Speech Simulation**\n",
        "def simulate_overlap(grouped_data, num_speakers=2, duration=10, sampling_rate=16000):\n",
        "    overlapping_segments = []\n",
        "    labels = []\n",
        "    for meeting_id, samples in grouped_data.items():\n",
        "        speakers = {sample[\"speaker_id\"]: [] for sample in samples}\n",
        "        for sample in samples:\n",
        "            speakers[sample[\"speaker_id\"]].append(sample)\n",
        "        if len(speakers) < num_speakers:\n",
        "            continue\n",
        "        for _ in range(50):\n",
        "            chosen_speakers = random.sample(list(speakers.keys()), num_speakers)\n",
        "            combined_signal = None\n",
        "            speaker_label = [0] * len(speakers)\n",
        "            for speaker_id in chosen_speakers:\n",
        "                sample = random.choice(speakers[speaker_id])\n",
        "                signal = sample[\"audio\"][\"array\"]\n",
        "                if len(signal) > duration * sampling_rate:\n",
        "                    signal = signal[: duration * sampling_rate]\n",
        "                else:\n",
        "                    signal = np.pad(signal, (0, duration * sampling_rate - len(signal)), mode=\"constant\")\n",
        "                if combined_signal is None:\n",
        "                    combined_signal = signal\n",
        "                else:\n",
        "                    combined_signal += signal\n",
        "                speaker_label[list(speakers.keys()).index(speaker_id)] = 1\n",
        "            if combined_signal is not None and np.max(np.abs(combined_signal)) > 0:\n",
        "                combined_signal = combined_signal / np.max(np.abs(combined_signal))\n",
        "            else:\n",
        "                continue\n",
        "            overlapping_segments.append(combined_signal)\n",
        "            labels.append(power_set_encoding(speaker_label))\n",
        "\n",
        "    # ✅ Debug: Print the first few labels to check if overlapping speech is simulated correctly\n",
        "    print(\"🔹 Sample labels from train set (Power-Set Encoded):\")\n",
        "    for i in range(min(10, len(labels))):  # Print up to 10 samples\n",
        "        print(labels[i])\n",
        "\n",
        "    return overlapping_segments, labels\n",
        "\n",
        "\n",
        "# **Feature Extraction (Log-Mel Spectrograms)**\n",
        "def extract_features_batch(segments, sr=16000, n_mels=80, win_length=0.025, hop_length=0.01, max_frames=None):\n",
        "    features = []\n",
        "    win_length_samples = int(win_length * sr)\n",
        "    hop_length_samples = int(hop_length * sr)\n",
        "\n",
        "    for segment in segments:\n",
        "        mel_spec = librosa.feature.melspectrogram(\n",
        "            y=segment, sr=sr, n_mels=n_mels, win_length=win_length_samples, hop_length=hop_length_samples\n",
        "        )\n",
        "        log_mel = librosa.power_to_db(mel_spec)\n",
        "\n",
        "        if max_frames:\n",
        "            log_mel = log_mel[:, :max_frames] if log_mel.shape[1] > max_frames else np.pad(\n",
        "                log_mel, ((0, 0), (0, max_frames - log_mel.shape[1])), mode=\"constant\"\n",
        "            )\n",
        "\n",
        "        features.append(log_mel.T)\n",
        "\n",
        "    features = np.array(features, dtype=np.float32)\n",
        "\n",
        "    return torch.tensor(features, dtype=torch.float32)  # ✅ Corrected tensor conversion\n",
        "\n",
        "class OverlappingSpeechDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        return feature, label\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()  # ✅ Mixed Precision Scaling\n",
        "\n",
        "# **Training Execution**\n",
        "num_speakers = 5\n",
        "\n",
        "# Simulate overlapping speech for training\n",
        "train_segments, train_labels = simulate_overlap(grouped_train)\n",
        "val_segments, val_labels = simulate_overlap(grouped_validation)\n",
        "test_segments, test_labels = simulate_overlap(grouped_test)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "print(\"🔹 Unique Labels in Training Set:\", set(train_labels))\n",
        "print(\"🔹 Label Distribution:\")\n",
        "label_counts = Counter(train_labels)\n",
        "for label, count in label_counts.items():\n",
        "    binary_repr = bin(label)[2:].zfill(num_speakers)  # Convert to binary\n",
        "    print(f\"Label: {label}, Binary: {binary_repr}, Count: {count}\")\n",
        "\n",
        "unique_labels = sorted(set(train_labels + val_labels))  # ✅ Include val_labels\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
        "\n",
        "print(f\"🔹 Label Mapping: {label_to_index}\")\n",
        "\n",
        "num_classes = len(unique_labels)  # ✅ Actual number of classes\n",
        "\n",
        "# Apply mapping to training and validation labels\n",
        "train_labels = [label_to_index[label] for label in train_labels]\n",
        "val_labels = [label_to_index[label] for label in val_labels]\n",
        "\n",
        "print(f\"🔹 Mapped Training Labels: {train_labels[:10]}\")  # Debugging\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn_pad(batch):\n",
        "    \"\"\"Pads variable-length sequences to the longest in the batch, ensuring consistent batch shapes.\"\"\"\n",
        "    batch = [b for b in batch if b is not None]  # Remove None samples\n",
        "\n",
        "    if len(batch) == 0:\n",
        "        return None, None  # Return empty batch if all are invalid\n",
        "\n",
        "    features, labels = zip(*batch)\n",
        "\n",
        "    # ✅ Pad sequences to the maximum length in this batch\n",
        "    features_padded = pad_sequence(features, batch_first=True, padding_value=0)\n",
        "\n",
        "    # ✅ Keep labels as scalars (no expansion)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return features_padded, labels\n",
        "\n",
        "\n",
        "max_frames = int((10 / 0.01))  # 10s duration, 0.01 hop length (10s / 10ms)\n",
        "train_features = extract_features_batch(train_segments, max_frames=max_frames)\n",
        "val_features = extract_features_batch(val_segments, max_frames=max_frames)\n",
        "test_features = extract_features_batch(test_segments, max_frames=max_frames)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    OverlappingSpeechDataset(train_features, train_labels),\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    OverlappingSpeechDataset(val_features, val_labels),\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    OverlappingSpeechDataset(test_features, test_labels),\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn_pad  # ✅ Apply collate function\n",
        ")\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ Define `speaker_encoder` correctly\n",
        "speaker_encoder = EncoderClassifier.from_hparams(\n",
        "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "    run_opts={\"device\": DEVICE}\n",
        ").to(DEVICE)\n",
        "\n",
        "# **SEND Model**\n",
        "class SpeechEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        return x\n",
        "\n",
        "class SEND(nn.Module):\n",
        "    def __init__(self, input_dim, speaker_dim, hidden_dim, num_layers, num_speakers):\n",
        "        super().__init__()\n",
        "        self.speech_encoder = SpeechEncoder(input_dim, hidden_dim, num_layers)\n",
        "        self.speaker_encoder = speaker_encoder.encode_batch\n",
        "\n",
        "        self.feature_projection = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n",
        "        self.context_independent = nn.Linear(hidden_dim * 2, num_speakers)\n",
        "        self.context_dependent = nn.TransformerEncoder(nn.TransformerEncoderLayer(hidden_dim * 2, 4), num_layers)\n",
        "        self.match_projection = nn.Linear(hidden_dim * 2, num_speakers)\n",
        "        self.post_net = nn.Linear(hidden_dim * 2, 2 ** num_speakers)  # Ensure input matches hidden_dim * 2\n",
        "\n",
        "    def forward(self, speech):\n",
        "        # Ensure correct shape\n",
        "        if speech.dim() == 4:\n",
        "            speech = speech.squeeze(1)\n",
        "\n",
        "        speech_features = self.speech_encoder(speech)\n",
        "        # print(f\"🔹 Speech features shape after LSTM: {speech_features.shape}\")  # [16, 29, 512]\n",
        "\n",
        "        speech_features = self.feature_projection(speech_features)\n",
        "        # print(f\"🔹 Projected speech features shape: {speech_features.shape}\")  # [16, 29, 512]\n",
        "\n",
        "        # **Apply mean pooling across time dimension (sequence length 29)**\n",
        "        pooled_features = torch.mean(speech_features, dim=1)  # [16, 512]\n",
        "        # print(f\"🔹 Pooled features shape: {pooled_features.shape}\")  # [16, 512]\n",
        "\n",
        "        # Ensure output matches batch size\n",
        "        output = self.post_net(pooled_features)  # [16, num_classes]\n",
        "        # print(f\"🔹 Model output shape: {output.shape}\")  # Should be [16, 2**num_speakers]\n",
        "\n",
        "        return output\n",
        "\n",
        "model = SEND(input_dim=80, speaker_dim=512, hidden_dim=256, num_layers=4, num_speakers=num_speakers).to(DEVICE)\n",
        "\n",
        "from pyannote.core import Annotation, Segment\n",
        "from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "\n",
        "def compute_der(predictions, ground_truths, timestamps):\n",
        "    metric = DiarizationErrorRate()\n",
        "    pred_annotation = Annotation()\n",
        "    gt_annotation = Annotation()\n",
        "\n",
        "    for i, (start, end) in enumerate(timestamps):\n",
        "        pred_annotation[Segment(start, end)] = str(predictions[i])\n",
        "        gt_annotation[Segment(start, end)] = str(ground_truths[i])\n",
        "\n",
        "    der_score = metric(gt_annotation, pred_annotation)\n",
        "    logging.info(f\"🔹 DER Computed: {der_score:.4f}\")\n",
        "    return der_score\n",
        "\n",
        "def labels_to_annotation(labels, num_speakers, frame_duration=0.01):\n",
        "    annotation = Annotation()\n",
        "\n",
        "    if isinstance(labels, (np.ndarray, torch.Tensor)):\n",
        "        labels = labels.flatten().tolist()  # Convert tensor to list\n",
        "\n",
        "    label = int(mode(labels, keepdims=True)[0][0])  # ✅ Fixed mode extraction\n",
        "    print(f\"🔹 Decoded Label: {label}\")\n",
        "\n",
        "    active_speakers = [bool(label & (1 << i)) for i in range(num_speakers)]\n",
        "\n",
        "    if isinstance(labels, (list, np.ndarray, torch.Tensor)):\n",
        "        end_time = len(labels) * frame_duration\n",
        "    else:\n",
        "        end_time = frame_duration  # Single label case\n",
        "\n",
        "    start_time = 0\n",
        "    for speaker_idx, is_active in enumerate(active_speakers):\n",
        "        if is_active:\n",
        "            annotation[Segment(start_time, end_time)] = f\"Speaker_{speaker_idx}\"\n",
        "\n",
        "    print(f\"Decoded label: {label}, Active speakers: {active_speakers}\")\n",
        "\n",
        "    return annotation\n",
        "\n",
        "def calculate_der(model, test_loader, num_speakers):\n",
        "    der_metric = DiarizationErrorRate()\n",
        "    total_der = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (features, labels) in enumerate(test_loader):\n",
        "            features = features.to(device)\n",
        "            outputs = model(features)\n",
        "            predicted_labels = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
        "            labels = labels.cpu().numpy()\n",
        "\n",
        "            for j in range(len(labels)):\n",
        "                ref_annotation = labels_to_annotation(labels[j], num_speakers)\n",
        "                hyp_annotation = labels_to_annotation(predicted_labels[j], num_speakers)\n",
        "\n",
        "                der = der_metric(ref_annotation, hyp_annotation)\n",
        "\n",
        "                logging.info(f\"🔹 Sample {i}-{j} | DER: {der:.2%}\")\n",
        "\n",
        "                total_der += der\n",
        "                num_samples += 1\n",
        "\n",
        "    avg_der = total_der / num_samples if num_samples > 0 else 0\n",
        "    logging.info(f\"\\n✅ Final Validation DER: {avg_der:.2%}\")\n",
        "    return avg_der\n",
        "\n",
        "\n",
        "class FLClient(NumPyClient):\n",
        "    def __init__(self, model, train_loader, test_loader):\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # ✅ Force CPU globally\n",
        "        self.device = torch.device(\"cpu\")  # ✅ Force CPU for PyTorch\n",
        "        logging.info(f\"Using device: {self.device}\")\n",
        "        self.model = model.to(self.device)  # ✅ Move model to CPU\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def get_parameters(self, config=None):\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        state_dict = {k: torch.tensor(v).to(self.device) for k, v in zip(self.model.state_dict().keys(), parameters)}\n",
        "        self.model.load_state_dict(state_dict)\n",
        "        self.model.to(self.device)  # Ensure model is on the right device\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.train()\n",
        "\n",
        "        logging.info(f\"Training on {self.device}...\")\n",
        "\n",
        "        # 🔹 Check initial weights before training\n",
        "        initial_weight = self.model.speech_encoder.lstm.weight_ih_l0.clone().detach().cpu()\n",
        "\n",
        "        total_loss = 0\n",
        "        for epoch in range(1):\n",
        "            for batch_idx, (features, labels) in enumerate(self.train_loader):\n",
        "                features, labels = features.to(self.device), labels.to(self.device)\n",
        "\n",
        "                logging.info(f\"Batch {batch_idx} \")\n",
        "                logging.info(f\"Sample labels: {labels[:5]}\")\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(features)\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=-1).cpu().tolist()  # 🔹 Get predictions\n",
        "\n",
        "                labels = labels.view(-1)\n",
        "                loss = self.criterion(outputs, labels.long())\n",
        "\n",
        "                print(f\"🔹 Batch {batch_idx} Loss: {loss.item()}\")  # ✅ Check if loss is meaningful\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                # 🔹 Check if predictions vary across batches\n",
        "                logging.info(f\"🔹 Predictions (Batch {batch_idx}): {preds[:5]}\")\n",
        "                logging.info(f\"🔹 Ground Truth: {labels[:5].tolist()}\")\n",
        "\n",
        "\n",
        "\n",
        "        avg_loss = total_loss / len(self.train_loader)\n",
        "\n",
        "        # 🔹 Check if weights changed after training\n",
        "        updated_weight = self.model.speech_encoder.lstm.weight_ih_l0.clone().detach().cpu()\n",
        "        weight_change = torch.sum((updated_weight - initial_weight) ** 2).item()\n",
        "\n",
        "        logging.info(f\"✅ Training completed. Avg Loss: {avg_loss:.4f}, Weight Change: {weight_change:.6f}\")\n",
        "\n",
        "        return self.get_parameters(), len(self.train_loader.dataset), {\"loss\": avg_loss, \"weight_change\": weight_change}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)  # Load the latest model parameters\n",
        "        self.model.eval()\n",
        "\n",
        "        logging.info(f\"🔹 Evaluating Model on {self.device}...\")\n",
        "\n",
        "        avg_der = calculate_der(self.model, self.test_loader, num_speakers)\n",
        "\n",
        "        logging.info(f\"✅ Evaluation Results - DER: {avg_der:.2%}\")\n",
        "\n",
        "        return 0.0, len(self.test_loader.dataset), {\"der\": avg_der}\n",
        "\n",
        "\n",
        "# ✅ Custom Strategy for Evaluation Debugging\n",
        "class PrintEvaluateStrategy(fl.server.strategy.FedAvg):\n",
        "    def aggregate_evaluate(self, rnd: int, results, failures):\n",
        "        aggregated = super().aggregate_evaluate(rnd, results, failures)\n",
        "        if aggregated is None:\n",
        "            logging.info(f\"[ROUND {rnd}] No evaluation results\")\n",
        "            return aggregated\n",
        "        if isinstance(aggregated, tuple):\n",
        "            if len(aggregated) == 3:\n",
        "                loss, num_examples, metrics = aggregated\n",
        "            elif len(aggregated) == 2:\n",
        "                loss, num_examples = aggregated\n",
        "                num_examples = num_examples if isinstance(num_examples, int) else \"unknown\"\n",
        "                metrics = {}\n",
        "            else:\n",
        "                loss, num_examples, metrics = aggregated, \"unknown\", {}\n",
        "        else:\n",
        "            logging.info(f\"[ROUND {rnd}] Aggregated evaluation: {aggregated}\")\n",
        "            return aggregated\n",
        "\n",
        "        accuracy = metrics.get(\"accuracy\", None)\n",
        "        accuracy_str = f\"{accuracy:.2%}\" if accuracy is not None else \"N/A\"\n",
        "        logging.info(f\"[ROUND {rnd}] Evaluation results: Loss: {loss:.4f}, Accuracy: {accuracy_str} on {num_examples} examples\")\n",
        "        return aggregated\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "strategy = PrintEvaluateStrategy(min_fit_clients=4, min_available_clients=4)\n",
        "\n",
        "for features, labels in train_loader:\n",
        "    print(f\"Feature shape: {features.shape}, Label shape: {labels.shape}\")\n",
        "    break  # Only check first batch\n",
        "\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=lambda ctx: FLClient(model, train_loader, test_loader),\n",
        "    num_clients=4,\n",
        "    config=fl.server.ServerConfig(num_rounds=2),\n",
        "    strategy=fl.server.strategy.FedAvg(),\n",
        "    ray_init_args={\n",
        "        \"num_cpus\": 4,  # ✅ Only use CPU\n",
        "        \"include_dashboard\": False,\n",
        "        \"ignore_reinit_error\": True,\n",
        "    },\n",
        "    client_resources={\"num_cpus\": 1}  # ✅ No GPU needed\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwIP7aHHJKE2",
        "outputId": "aa8afcab-f878-481b-874c-3c3dc865e0fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  stats = torch.load(path, map_location=device)\n",
            "<ipython-input-10-272fc8c28c40>:129: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()  # ✅ Mixed Precision Scaling\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Sample labels from train set (Power-Set Encoded):\n",
            "10\n",
            "3\n",
            "3\n",
            "12\n",
            "20\n",
            "17\n",
            "9\n",
            "18\n",
            "20\n",
            "6\n",
            "🔹 Sample labels from train set (Power-Set Encoded):\n",
            "3\n",
            "6\n",
            "3\n",
            "12\n",
            "5\n",
            "3\n",
            "10\n",
            "3\n",
            "3\n",
            "3\n",
            "🔹 Sample labels from train set (Power-Set Encoded):\n",
            "3\n",
            "6\n",
            "12\n",
            "10\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "6\n",
            "5\n",
            "🔹 Unique Labels in Training Set: {3, 5, 6, 9, 10, 12, 17, 18, 20, 24}\n",
            "🔹 Label Distribution:\n",
            "Label: 10, Binary: 01010, Count: 32\n",
            "Label: 3, Binary: 00011, Count: 21\n",
            "Label: 12, Binary: 01100, Count: 23\n",
            "Label: 20, Binary: 10100, Count: 14\n",
            "Label: 17, Binary: 10001, Count: 14\n",
            "Label: 9, Binary: 01001, Count: 25\n",
            "Label: 18, Binary: 10010, Count: 12\n",
            "Label: 6, Binary: 00110, Count: 20\n",
            "Label: 24, Binary: 11000, Count: 15\n",
            "Label: 5, Binary: 00101, Count: 24\n",
            "🔹 Label Mapping: {3: 0, 5: 1, 6: 2, 9: 3, 10: 4, 12: 5, 17: 6, 18: 7, 20: 8, 24: 9}\n",
            "🔹 Mapped Training Labels: [4, 0, 0, 5, 8, 6, 3, 7, 8, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "<ipython-input-10-272fc8c28c40>:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "WARNING:flwr:DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=2, no round_timeout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shape: torch.Size([1, 1000, 80]), Label shape: torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-28 10:53:08,853\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 4.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'memory': 32625102030.0, 'object_store_memory': 16312551014.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 4 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=11998)\u001b[0m 2025-02-28 10:53:11.204695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=11998)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=11998)\u001b[0m E0000 00:00:1740739991.249493   11998 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=11998)\u001b[0m E0000 00:00:1740739991.263285   11998 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m /usr/local/lib/python3.11/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m   cm = get_cmap(\"Set1\")\n",
            "\u001b[36m(pid=11999)\u001b[0m 2025-02-28 10:53:11.535159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(pid=11999)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=11999)\u001b[0m E0000 00:00:1740739991.585181   11999 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=11999)\u001b[0m E0000 00:00:1740739991.598159   11999 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m /usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m   wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Training on cpu...\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m <ipython-input-10-272fc8c28c40>:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 0 \n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([4])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 0 Loss: 3.453615188598633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 0): [0]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 1 \n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 1 Loss: 3.393639087677002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m /usr/local/lib/python3.11/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m   cm = get_cmap(\"Set1\")\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 1): [4]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [0]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 2 \n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([1])\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m /usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m   wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 2 Loss: 3.5189402103424072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m /usr/local/lib/python3.11/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m   cm = get_cmap(\"Set1\")\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 2): [4]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 3 \n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([7])\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Training on cpu...\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m <ipython-input-10-272fc8c28c40>:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 0 \n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 3 Loss: 3.593151569366455\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 0 Loss: 3.4775266647338867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 0): [0]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [3]\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m /usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m   wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Using device: cpu\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m /usr/local/lib/python3.11/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m   cm = get_cmap(\"Set1\")\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Training on cpu...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m <ipython-input-10-272fc8c28c40>:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 2 \u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 2 Loss: 3.3835034370422363\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 3): [0]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 6 \u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 6 Loss: 3.825582504272461\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 6): [4]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 9 \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 9 Loss: 3.754826068878174\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 8): [4]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 10 \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 10 Loss: 5.583727836608887\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 10): [5]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 12 \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 12 Loss: 1.9239444732666016\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 12): [5]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 14 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 14 Loss: 2.9792189598083496\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 15): [4]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 18 \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 18 Loss: 3.07169246673584\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 17): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 20 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 20 Loss: 2.163658618927002\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 17): [8]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 19 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 19 Loss: 2.926764488220215\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 19): [5]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 24 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 24 Loss: 3.074634552001953\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 22): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 26 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 22 Loss: 2.943615436553955\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 22): [7]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 24 \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 24 Loss: 2.7782535552978516\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 24): [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 26 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 26 Loss: 1.5178409814834595\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 27): [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 29 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 29 Loss: 2.8187642097473145\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 29): [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 29 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 29 Loss: 2.569267749786377\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 32): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 33 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 33 Loss: 1.8786542415618896\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 34): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 36 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 36 Loss: 2.1813814640045166\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 36): [3]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 34 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 36 Loss: 3.607941150665283\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 35): [3]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 36 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 36 Loss: 4.356205940246582\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 36): [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 37 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 37 Loss: 2.7929155826568604\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 40): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 41 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 41 Loss: 2.317884683609009\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 39): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 40 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 40 Loss: 4.79234504699707\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 43): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 44 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 44 Loss: 2.08278751373291\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 45): [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 46 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 46 Loss: 2.7626428604125977\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 44): [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 45 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 44 Loss: 1.7058061361312866\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 46): [0]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 47 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 47 Loss: 2.4728732109069824\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 46): [8]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 47 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 47 Loss: 3.7082390785217285\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 49): [0]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 50 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 50 Loss: 4.276923179626465\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 54): [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 55 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 55 Loss: 1.6433521509170532\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 52): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 53 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 53 Loss: 2.4232258796691895\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 57): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 58 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 53 Loss: 3.7330031394958496\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 58): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 59 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 59 Loss: 2.278280258178711\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 55): [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 56 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 56 Loss: 3.136037826538086\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 57): [5]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 58 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 58 Loss: 2.61732816696167\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 62): [0]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 63 \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 63 Loss: 2.4394376277923584\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 66): [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 67 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 67 Loss: 1.4234532117843628\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 63): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 64 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 64 Loss: 2.1843466758728027\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 69): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 70 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 70 Loss: 4.68317174911499\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 71): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 72 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 72 Loss: 2.3078489303588867\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 65): [5]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 66 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 74 Loss: 3.0828857421875\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 71 Loss: 2.175910472869873\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 75): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 76 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 72 Loss: 2.07906436920166\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 68): [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 69 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 73 Loss: 2.1133456230163574\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 69): [5]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 70 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 79 Loss: 2.502840995788574\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 73): [5]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 74 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 74): [3]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 75 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 80 Loss: 2.1179542541503906\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 80): [4]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 81 \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 81 Loss: 2.523627758026123\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 76): [3]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 77 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 82 Loss: 2.0150537490844727\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 74): [5]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 75 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 75 Loss: 1.9292001724243164\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 79): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 80 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 80 Loss: 2.1492388248443604\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 77): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 78 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 78 Loss: 4.295682430267334\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 82): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 83 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 83 Loss: 1.7343469858169556\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 83): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 84 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 90 Loss: 2.9401040077209473\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 85): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 86 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 86 Loss: 1.7477298974990845\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 82): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 83 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 83 Loss: 1.8798068761825562\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 88): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 89 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 89 Loss: 2.7768568992614746\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 89): [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 90 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 96 Loss: 2.3178470134735107\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 96): [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 97 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 88 Loss: 2.8851847648620605\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 88): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 89 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 94 Loss: 1.5182000398635864\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 94): [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 95 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 95 Loss: 2.582306385040283\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 100): [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 101 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 96 Loss: 2.7077717781066895\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 96): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 97 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 93 Loss: 2.1534109115600586\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 99): [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 100 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 94 Loss: 2.9072678089141846\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 104): [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 105 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 100 Loss: 2.0369770526885986\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 102): [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 103 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 101 Loss: 2.0045979022979736\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 101): [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 102 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 99 Loss: 2.131337881088257\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 99): [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 100 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 106 Loss: 3.573652744293213\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 104): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 105 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 112 Loss: 2.4294426441192627\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 105): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 106 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 103 Loss: 2.4519736766815186\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 103): [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 104 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 108 Loss: 2.252781867980957\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 115): [8]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 116 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 111 Loss: 2.503141164779663\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 111): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 112 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 111 Loss: 2.713196277618408\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 111): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 112 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 119 Loss: 2.493488073348999\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 108): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 109 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 121 Loss: 2.611931085586548\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 114): [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 115 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 111 Loss: 3.0232748985290527\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 115): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 116 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 119 Loss: 2.267056703567505\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 112): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 113 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 125 Loss: 2.546553611755371\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 113): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 114 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 119 Loss: 1.9605190753936768\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 114): [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 115 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 128 Loss: 2.209177255630493\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 120): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 121 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 124 Loss: 2.6860132217407227\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 129): [8]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 130 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 118 Loss: 2.1899402141571045\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 123): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 124 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 127 Loss: 2.210157871246338\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 119): [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 120 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 126 Loss: 2.529491901397705\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 126): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 127 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 130 Loss: 2.8420844078063965\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 122): [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 123 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 132 Loss: 2.4223392009735107\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 123): [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 124 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 125 Loss: 1.981001377105713\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 138): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 139 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 132 Loss: 2.201899290084839\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 126): [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 127 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 127): [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 128 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 134 Loss: 1.6738353967666626\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 143): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 144 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 144 Loss: 2.916369676589966\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 130): [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 131 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 131 Loss: 2.5894906520843506\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 141): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 142 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 147 Loss: 2.2637686729431152\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 133): [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 134 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 134 Loss: 2.8561224937438965\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 149): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 150 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 150 Loss: 2.7542672157287598\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 142): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 143 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 143 Loss: 2.4519405364990234\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 152): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 153 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 153 Loss: 2.561345100402832\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 145): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 146 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 146 Loss: 2.255605936050415\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 155): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 156 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 156 Loss: 1.9867743253707886\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 151): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 152 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 152 Loss: 3.0233945846557617\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 149): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 150 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 150 Loss: 2.7427124977111816\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 160): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 161 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 161 Loss: 2.767362594604492\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 145): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 146 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 156 Loss: 2.113615036010742\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 157 Loss: 2.670438528060913\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 163): [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 164 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 154): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 155 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 155 Loss: 2.0730185508728027\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 159): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 160 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 160 Loss: 2.5705313682556152\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 168): [5]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 169 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 169 Loss: 1.6060012578964233\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 170): [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 171 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 171 Loss: 2.71262788772583\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 161): [5]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 162 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 162 Loss: 2.41867733001709\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 162): [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 163 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 163 Loss: 2.929638385772705\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 167): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 168 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 168 Loss: 2.18208646774292\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 157): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 158 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 158 Loss: 2.307366371154785\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 171): [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 172 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 172 Loss: 2.311631441116333\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 168): [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 169 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 169 Loss: 2.318180561065674\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 161): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 162 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 162 Loss: 1.8234912157058716\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 162): [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 163 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 172 Loss: 2.199310302734375\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 172): [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 173 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 177 Loss: 2.3436970710754395\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 165): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 166 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 166 Loss: 2.4363343715667725\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 175): [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 176 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 176 Loss: 1.994053602218628\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 180): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 181 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 188 Loss: 2.312870979309082\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 181): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 182 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 182 Loss: 2.1819450855255127\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 190): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 191 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 191 Loss: 1.7936320304870605\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 192): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 193 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 193 Loss: 2.7730860710144043\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 186): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 187 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 187 Loss: 2.800961494445801\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 184): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 185 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 185 Loss: 2.539602518081665\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 185): [3]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 186 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 197 Loss: 2.3601839542388916\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 190): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 191 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 191 Loss: 2.4331798553466797\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 178): [9]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 179 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 189 Loss: 2.444746971130371\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:✅ Training completed. Avg Loss: 2.5608, Weight Change: 2.711470\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 189): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 190 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 181 Loss: 2.4690322875976562\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 190): [3]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 191 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 182 Loss: 2.158336639404297\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 192): [3]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 193 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 197 Loss: 1.9815512895584106\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 197): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 198 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 195 Loss: 2.5541763305664062\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 195): [2]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 196 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:✅ Training completed. Avg Loss: 2.5690, Weight Change: 2.818293\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 186): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 187 \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 197 Loss: 2.007974147796631\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 198 Loss: 3.241513252258301\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 188): [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 189 \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 189): [1]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 190 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 190 Loss: 2.9970192909240723\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:✅ Training completed. Avg Loss: 2.5861, Weight Change: 2.488652\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 191): [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 192 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 192 Loss: 2.1715290546417236\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 193): [1]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 194 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 194 Loss: 2.190319776535034\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 195): [1]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 196 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 196 Loss: 2.2689802646636963\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 197): [0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 198 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 198 Loss: 2.0817646980285645\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:✅ Training completed. Avg Loss: 2.6517, Weight Change: 2.696616\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 199): [0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 199 \n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([4])\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Evaluating Model on cpu...\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m <ipython-input-10-272fc8c28c40>:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m /usr/local/lib/python3.11/dist-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Sample 0-0 | DER: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 3\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 199 Loss: 2.221144437789917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Sample 1-0 | DER: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 6\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Sample 2-0 | DER: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 12\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Using device: cpu\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Evaluating Model on cpu...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m <ipython-input-10-272fc8c28c40>:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m /usr/local/lib/python3.11/dist-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m   warnings.warn(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Sample 10-0 | DER: 0.00%\u001b[32m [repeated 26x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 52x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Sample 20-0 | DER: 0.00%\u001b[32m [repeated 38x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 24-0 | DER: 0.00%\u001b[32m [repeated 41x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 34-0 | DER: 0.00%\u001b[32m [repeated 38x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 43-0 | DER: 0.00%\u001b[32m [repeated 35x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 39x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 53-0 | DER: 0.00%\u001b[32m [repeated 39x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 38x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 62-0 | DER: 0.00%\u001b[32m [repeated 38x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 71-0 | DER: 0.00%\u001b[32m [repeated 39x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 39x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 81-0 | DER: 0.00%\u001b[32m [repeated 39x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 38x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 90-0 | DER: 0.00%\u001b[32m [repeated 38x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 99-0 | DER: 0.00%\u001b[32m [repeated 39x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 105-0 | DER: 0.00%\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 113-0 | DER: 0.00%\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Sample 132-0 | DER: 0.00%\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 128-0 | DER: 0.00%\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 135-0 | DER: 0.00%\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 143-0 | DER: 0.00%\u001b[32m [repeated 37x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 164-0 | DER: 0.00%\u001b[32m [repeated 41x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 173-0 | DER: 0.00%\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 72x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 183-0 | DER: 0.00%\u001b[32m [repeated 39x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 193-0 | DER: 0.00%\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m ✅ Final Validation DER: 0.00%\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:✅ Evaluation Results - DER: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 193-0 | DER: 0.00%\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m ✅ Final Validation DER: 0.00%\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:✅ Evaluation Results - DER: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 52x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m ✅ Final Validation DER: 0.00%\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:✅ Evaluation Results - DER: 0.00%\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 199-0 | DER: 0.00%\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Training on cpu...\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m <ipython-input-10-272fc8c28c40>:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 0 \n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 0 Loss: 2.445739507675171\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m ✅ Final Validation DER: 0.00%\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:✅ Evaluation Results - DER: 0.00%\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 0): [4]\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [0]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Using device: cpu\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Training on cpu...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m <ipython-input-10-272fc8c28c40>:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 1 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 1 Loss: 2.0941567420959473\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 1): [4]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 3 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 3 Loss: 2.577475070953369\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 3): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 5 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 5 Loss: 2.576594591140747\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 6): [2]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 7 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 7 Loss: 1.4481040239334106\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 8): [2]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 9 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 9 Loss: 2.3214588165283203\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 9): [8]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 10 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 11 Loss: 3.113940715789795\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 11): [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 12 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 11 Loss: 2.330721378326416\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 12): [2]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 13 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 14 Loss: 2.812089443206787\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 14): [8]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 15 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 15 Loss: 3.40997052192688\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 15): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 16 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 17 Loss: 2.29488468170166\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 17): [2]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 18 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 19 Loss: 3.1983437538146973\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 18): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 19 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 20 Loss: 2.548921585083008\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 21): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 22 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 21 Loss: 2.040538787841797\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 22): [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 23 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 24 Loss: 2.1707558631896973\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 24): [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 25 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 25 Loss: 2.498621940612793\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 24): [0]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 25 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 27 Loss: 2.567976951599121\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 27): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 28 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 27 Loss: 2.6991658210754395\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 28): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 29 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 30 Loss: 2.4181084632873535\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 30): [2]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 31 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 31 Loss: 2.8408212661743164\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 32): [2]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 33 \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 33 Loss: 2.3582630157470703\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 33): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 34 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 34 Loss: 2.1651155948638916\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 34): [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 35 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 35 Loss: 2.290052652359009\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 36): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 37 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 37 Loss: 2.4033217430114746\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 37): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 38 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 38 Loss: 2.521390438079834\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 40): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 41 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 41 Loss: 2.257441520690918\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 40): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 41 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 41 Loss: 2.409806251525879\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 43): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 44 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 44 Loss: 2.4952447414398193\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 43): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 44 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 44 Loss: 3.2905778884887695\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 45): [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 46 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 46 Loss: 1.9351656436920166\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 47): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 48 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 48 Loss: 2.211763858795166\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 47): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 48 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 48 Loss: 2.5846951007843018\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 49): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 50 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 51 Loss: 2.84950590133667\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 50): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 51 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 52 Loss: 3.1070432662963867\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 52): [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 53 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 53 Loss: 3.061253547668457\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 54): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 55 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 55 Loss: 2.341850757598877\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 55): [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 56 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 56 Loss: 2.012998342514038\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 55): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 56 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 56 Loss: 2.0960309505462646\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 57): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 58 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 58 Loss: 3.013979196548462\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 60): [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 61 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 61 Loss: 2.644660711288452\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 60): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 61 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 61 Loss: 2.0804970264434814\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 63): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 64 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 61 Loss: 1.9327353239059448\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 64): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 65 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 65 Loss: 2.478754997253418\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 64): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 65 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 65 Loss: 2.5087246894836426\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 64): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 65 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 65 Loss: 2.2788803577423096\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 69): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 70 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 70 Loss: 2.9136364459991455\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 68): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 69 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 69 Loss: 2.45212721824646\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 69): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 70 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 73 Loss: 2.6516520977020264\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 69): [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 70 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 72 Loss: 2.4761855602264404\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 75): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 76 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 76 Loss: 2.342794179916382\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 74): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 75 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 75 Loss: 1.8983572721481323\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 78): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 79 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 79 Loss: 2.27431321144104\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 79): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 80 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 75 Loss: 2.7634353637695312\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 75): [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 76 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 76 Loss: 2.3258707523345947\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 80): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 81 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 81 Loss: 2.133507251739502\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 81): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 82 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 85 Loss: 2.549647331237793\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 85): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 86 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 84 Loss: 2.379922389984131\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 80): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 81 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 86 Loss: 1.8904917240142822\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 85): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 86 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 88 Loss: 2.1888208389282227\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 83): [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 84 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 88 Loss: 2.5048727989196777\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 91): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 92 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 86 Loss: 2.0994787216186523\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 92): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 93 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 94 Loss: 2.314420700073242\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 87): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 88 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 95 Loss: 2.544203281402588\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 92): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 93 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 93 Loss: 2.9158432483673096\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 94): [0]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 95 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 95 Loss: 2.848651170730591\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 91): [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 92 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 92 Loss: 2.1355512142181396\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 97): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 98 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 98 Loss: 2.5864944458007812\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 102): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 103 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 103 Loss: 2.5351834297180176\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 95): [1]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 96 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 96 Loss: 2.381925106048584\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 105): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 106 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 106 Loss: 1.9517136812210083\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 103): [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 104 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 104 Loss: 2.1645050048828125\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 107): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 108 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 108 Loss: 3.0543389320373535\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 108): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 109 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 109 Loss: 2.3419575691223145\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 110): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 111 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 111 Loss: 1.9557782411575317\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 112): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 113 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 113 Loss: 1.5580240488052368\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 110): [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 111 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 111 Loss: 2.692648410797119\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 111): [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 112 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 112 Loss: 2.751549482345581\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 112): [0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 113 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 117 Loss: 2.5781936645507812\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 117): [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 118 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 118 Loss: 2.37099552154541\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 110): [3]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 111 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 119 Loss: 2.4316794872283936\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 116): [0]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 117 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 117 Loss: 2.283794403076172\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 113): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 114 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 114 Loss: 2.1772093772888184\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 114): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 115 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 115 Loss: 3.4111533164978027\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 124): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 125 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 125 Loss: 2.386341094970703\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 117): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 118 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 118 Loss: 3.011873960494995\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 127): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 128 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 128 Loss: 2.458885669708252\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 128): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 129 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 129 Loss: 2.369516611099243\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 129): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 130 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 130 Loss: 2.2925710678100586\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 130): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 131 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 132 Loss: 2.3418428897857666\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 123): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 124 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 133 Loss: 1.6767827272415161\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 133): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 134 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 134 Loss: 2.307765007019043\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 134): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 135 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 127 Loss: 2.1041290760040283\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 127): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 128 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 137 Loss: 2.234959602355957\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 137): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 138 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 139 Loss: 1.6247079372406006\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 139): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 140 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 136 Loss: 2.636753797531128\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 131): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 132 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 137 Loss: 2.7447009086608887\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 133): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 134 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 143 Loss: 2.2825164794921875\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 138): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 139 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 144 Loss: 2.2725436687469482\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 139): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 140 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 145 Loss: 2.2518863677978516\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 137): [3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 138 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 147 Loss: 2.23675799369812\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 147): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 148 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 143 Loss: 2.623300790786743\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 148): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 149 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 141 Loss: 2.316849708557129\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 150): [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 151 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 142 Loss: 2.459306240081787\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 151): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 152 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 152 Loss: 2.5073068141937256\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 153): [3]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 154 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 154 Loss: 2.5017404556274414\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 148): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 149 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 149 Loss: 2.5277442932128906\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 155): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 156 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 156 Loss: 1.5990464687347412\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 151): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 152 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 152 Loss: 2.1614012718200684\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 160): [4]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 161 \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 161 Loss: 2.334787607192993\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 154): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 155 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 162 Loss: 2.1361899375915527\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 161): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 162 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 162 Loss: 2.528319835662842\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 164): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 154 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 165 Loss: 2.283282995223999\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 165): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 166 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 165 Loss: 1.545742392539978\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 165): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 166 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 161 Loss: 2.7632553577423096\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 166): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 167 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 162 Loss: 2.3614416122436523\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 168): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 169 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 159 Loss: 2.594303607940674\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 159): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [8]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 160 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 171 Loss: 2.5098800659179688\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 171): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 172 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 172 Loss: 2.4635446071624756\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 162): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 163 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 174 Loss: 2.1723415851593018\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 174): [4]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 175 \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 175 Loss: 2.2365336418151855\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 175): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 176 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 165 Loss: 2.3197193145751953\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 165): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 166 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 178 Loss: 2.236097574234009\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 166): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 167 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 179 Loss: 1.6185210943222046\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 172): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [3]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 173 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 173): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 174 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 174 Loss: 2.3457770347595215\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 174): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 175 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 175 Loss: 2.939335823059082\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 175): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 176 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 176 Loss: 2.182623863220215\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 176): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 177 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([6])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 177 Loss: 2.92490816116333\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 174 Loss: 2.340019464492798\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 185): [4]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 186 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 186): [4]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 187 \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([0])\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 187 Loss: 2.1627182960510254\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 187): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [0]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 188 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Batch 189 Loss: 2.5413103103637695\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 189): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [9]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 190 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 182 Loss: 1.9442583322525024\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 178): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 179 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 183 Loss: 1.6809359788894653\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Predictions (Batch 192): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Batch 193 \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 192 Loss: 2.518862247467041\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 181): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [6]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 182 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([3])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 182 Loss: 2.356243848800659\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 195): [4]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Batch 196 \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:Sample labels: tensor([8])\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Batch 196 Loss: 2.8164193630218506\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 188): [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 189 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 189 Loss: 3.192516565322876\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 189): [4]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 190 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 190 Loss: 1.6948455572128296\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:✅ Training completed. Avg Loss: 2.3597, Weight Change: 1.509591\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Predictions (Batch 199): [4]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 187 \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([9])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:✅ Training completed. Avg Loss: 2.3444, Weight Change: 1.916543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 192 Loss: 2.1414926052093506\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Predictions (Batch 192): [4]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Batch 193 \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:Sample labels: tensor([2])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 189): [4]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [2]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 190 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 190 Loss: 1.7273520231246948\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 190): [4]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 191 \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 191 Loss: 2.565107822418213\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 192): [4]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 193 \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Batch 197 Loss: 2.826266288757324\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 193): [4]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 194 \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([5])\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 194 Loss: 2.1709177494049072\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 194): [4]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [5]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 195 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([7])\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 195 Loss: 2.7500367164611816\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:✅ Training completed. Avg Loss: 2.3704, Weight Change: 1.888592\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 195): [4]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [7]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 196 \n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 196 Loss: 2.4714198112487793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 197 \n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([8])\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 196): [4]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 197 Loss: 2.5769407749176025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 197): [4]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [8]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 198 \n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 198 Loss: 2.4072418212890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 198): [4]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [3]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Batch 199 \n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Sample labels: tensor([4])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Batch 199 Loss: 1.8805278539657593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Predictions (Batch 199): [4]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Ground Truth: [4]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:✅ Training completed. Avg Loss: 2.3639, Weight Change: 1.686778\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Evaluating Model on cpu...\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m <ipython-input-10-272fc8c28c40>:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 0-0 | DER: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Decoded Label: 3\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Decoded Label: 4\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 1-0 | DER: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Decoded Label: 6\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m 🔹 Decoded Label: 4\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:Using device: cpu\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Evaluating Model on cpu...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m <ipython-input-10-272fc8c28c40>:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 9-0 | DER: 0.00%\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 15-0 | DER: 0.00%\u001b[32m [repeated 35x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Sample 22-0 | DER: 0.00%\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 72x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 68x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 33-0 | DER: 0.00%\u001b[32m [repeated 34x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 72x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 42-0 | DER: 0.00%\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 72x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 51-0 | DER: 0.00%\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 61-0 | DER: 0.00%\u001b[32m [repeated 34x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 68x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 70-0 | DER: 0.00%\u001b[32m [repeated 35x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 79-0 | DER: 0.00%\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 72x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 88-0 | DER: 0.00%\u001b[32m [repeated 35x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 96-0 | DER: 0.00%\u001b[32m [repeated 37x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 106-0 | DER: 0.00%\u001b[32m [repeated 35x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 68x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 34x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 113-0 | DER: 0.00%\u001b[32m [repeated 34x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 123-0 | DER: 0.00%\u001b[32m [repeated 35x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 35x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 131-0 | DER: 0.00%\u001b[32m [repeated 35x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 72x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 140-0 | DER: 0.00%\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 149-0 | DER: 0.00%\u001b[32m [repeated 37x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 35x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m INFO:root:🔹 Sample 158-0 | DER: 0.00%\u001b[32m [repeated 35x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:🔹 Sample 168-0 | DER: 0.00%\u001b[32m [repeated 37x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m INFO:root:🔹 Sample 172-0 | DER: 0.00%\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\n",
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 183-0 | DER: 0.00%\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=11997)\u001b[0m INFO:root:🔹 Sample 192-0 | DER: 0.00%\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 12, Active speakers: [False, False, True, True, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m 🔹 Decoded Label: 4\u001b[32m [repeated 72x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 4, Active speakers: [False, False, True, False, False]\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 10, Active speakers: [False, True, False, True, False]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m Decoded label: 6, Active speakers: [False, True, True, False, False]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11998)\u001b[0m Decoded label: 9, Active speakers: [True, False, False, True, False]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 3, Active speakers: [True, True, False, False, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m ✅ Final Validation DER: 0.00%\n",
            "\u001b[36m(ClientAppActor pid=12000)\u001b[0m INFO:root:✅ Evaluation Results - DER: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=11999)\u001b[0m Decoded label: 5, Active speakers: [True, False, True, False, False]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 2 round(s) in 1922.50s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.0\n",
              "\tround 2: 0.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}