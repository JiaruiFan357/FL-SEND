{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrmEzVwjFI0t"
      },
      "source": [
        "# Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nqkl2UWGdgP",
        "outputId": "2d4a1e8a-70ad-428d-b2a8-7ae7244ee550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: flwr 1.15.2\n",
            "Uninstalling flwr-1.15.2:\n",
            "  Successfully uninstalled flwr-1.15.2\n",
            "Found existing installation: ray 2.31.0\n",
            "Uninstalling ray-2.31.0:\n",
            "  Successfully uninstalled ray-2.31.0\n",
            "Collecting ray\n",
            "  Using cached ray-2.42.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting flwr[simulation]\n",
            "  Using cached flwr-1.15.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: cryptography<44.0.0,>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (43.0.3)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.70.0)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.0.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.26.4)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (4.25.6)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (3.21.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (6.0.2)\n",
            "Collecting ray\n",
            "  Using cached ray-2.31.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray) (3.17.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray) (24.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray) (1.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44.0.0,>=43.0.1->flwr[simulation]) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (4.12.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (0.22.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->flwr[simulation]) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation]) (0.1.2)\n",
            "Using cached ray-2.31.0-cp311-cp311-manylinux2014_x86_64.whl (66.7 MB)\n",
            "Using cached flwr-1.15.2-py3-none-any.whl (531 kB)\n",
            "Installing collected packages: ray, flwr\n",
            "Successfully installed flwr-1.15.2 ray-2.31.0\n",
            "Requirement already satisfied: pyannote.metrics in /usr/local/lib/python3.11/dist-packages (3.2.1)\n",
            "Requirement already satisfied: pyannote.core>=4.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (5.1.3)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (1.6.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (3.10.0)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.metrics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.metrics) (2025.1)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=4.1->pyannote.metrics) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=4.1->pyannote.metrics) (4.12.2)\n",
            "Requirement already satisfied: pyYAML>=3.12 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics) (6.0.2)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics) (0.12.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.1->pyannote.metrics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics) (0.1.2)\n",
            "Requirement already satisfied: pyannote.core in /usr/local/lib/python3.11/dist-packages (5.0.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core) (4.12.2)\n",
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (2.32.3)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain) (0.18.10)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y flwr ray\n",
        "!pip install -U \"flwr[simulation]\" ray\n",
        "!pip install pyannote.metrics\n",
        "!pip install pyannote.core\n",
        "!pip install speechbrain\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZlNIJ-CBp0Q",
        "outputId": "a3d892b7-f70d-46f1-9481-44a9a606875f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyannote/core/notebook.py:134: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  cm = get_cmap(\"Set1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-9f74519d6701>:21: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
            "  from speechbrain.pretrained import EncoderClassifier\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import flwr as fl\n",
        "from flwr.client import NumPyClient\n",
        "from flwr.common import Context\n",
        "from pyannote.core import Segment, Annotation\n",
        "from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# **Set device**\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Training on {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj2Tr1X9FQ3c"
      },
      "source": [
        "# Load and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ReD7Jn5MXYr",
        "outputId": "b20bdbe7-8649-4369-e9c2-5a43c8f47cfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: read).\n",
            "The token `pycharm` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `pycharm`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "311sAis3QvBT"
      },
      "outputs": [],
      "source": [
        "def power_set_encoding(labels):\n",
        "    \"\"\"Encodes speaker pairs into a fixed label mapping.\"\"\"\n",
        "    if not labels or not isinstance(labels, list):\n",
        "        print(f\"❌ Invalid labels: {labels}\")  # Debug\n",
        "        return 0  # If no one is speaking, return 0\n",
        "\n",
        "    # ✅ Standardize sorting to avoid different orders\n",
        "    labels = sorted(labels)\n",
        "\n",
        "    # ✅ Define the mapping explicitly\n",
        "    encoding_map = {\n",
        "        tuple(): 0,     # No one speaking\n",
        "        (\"A\", \"A\"): 1,  # Speaker A alone\n",
        "        (\"B\", \"B\"): 2,  # Speaker B alone\n",
        "        (\"A\", \"B\"): 3   # Both speakers\n",
        "    }\n",
        "\n",
        "    # 🔹 Convert list to tuple for lookup\n",
        "    encoded_label = encoding_map.get(tuple(labels), -1)\n",
        "\n",
        "    # ✅ If label is not found, print error and return fallback\n",
        "    if encoded_label == -1:\n",
        "        print(f\"❌ Unexpected speaker combination: {labels}, setting to 0\")\n",
        "        encoded_label = 0  # Default to silence if unexpected case appears\n",
        "\n",
        "    return encoded_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUpr48rAPXGa",
        "outputId": "da7261f7-19f9-4fa2-fc0b-fa9618f99cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total extracted segments: 13358\n"
          ]
        }
      ],
      "source": [
        "# Load preprocessed dataset\n",
        "with open(\"preprocessed_callhome_data.pkl\", \"rb\") as f:\n",
        "    preprocessed_data = pickle.load(f)\n",
        "extracted_segments = preprocessed_data.get(\"extracted_segments\", [])\n",
        "print(f\"Total extracted segments: {len(extracted_segments)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPeLlsVdVZVv",
        "outputId": "c305c3c8-0705-45f4-95f4-9d674c93e353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Unique speaker labels in dataset: {'B2', 'A1', 'A', 'B', 'B1'}\n"
          ]
        }
      ],
      "source": [
        "# Collect unique speaker labels\n",
        "unique_speaker_labels = set()\n",
        "\n",
        "for seg in extracted_segments:\n",
        "    unique_speaker_labels.update(seg[\"speakers\"])\n",
        "\n",
        "print(f\"🔍 Unique speaker labels in dataset: {unique_speaker_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gKHG2wf8f2jW"
      },
      "outputs": [],
      "source": [
        "for seg in extracted_segments:\n",
        "    seg[\"speakers\"] = [\"A\" if s == \"A1\" else \"B\" if s == \"B1\" or s == \"B2\" else s for s in seg[\"speakers\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tR-7xHlgoyL",
        "outputId": "316bdf37-4da4-42a8-dd76-21f3b2ffe343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Unique speaker labels in dataset: {'A', 'B'}\n"
          ]
        }
      ],
      "source": [
        "# Collect unique speaker labels\n",
        "unique_speaker_labels = set()\n",
        "\n",
        "for seg in extracted_segments:\n",
        "    unique_speaker_labels.update(seg[\"speakers\"])\n",
        "\n",
        "print(f\"🔍 Unique speaker labels in dataset: {unique_speaker_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn6FnKvbOaB9",
        "outputId": "0eebfcb3-4260-44ac-ce39-db94f62631fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Segment 0 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 1 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 2 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 3 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 4 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 5 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 6 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 7 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 8 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 9 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 10 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 11 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 12 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 13 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 14 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 15 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 16 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 17 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 18 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 19 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 20 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 21 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 22 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 23 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 24 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 25 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 26 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 27 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 28 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 29 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 30 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 31 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 32 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 33 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 34 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 35 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 36 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 37 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 38 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 39 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 40 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 41 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 42 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 43 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 44 Speakers: ['B', 'A'], Encoded Label: 3\n",
            "🔍 Segment 45 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 46 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 47 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 48 Speakers: ['A', 'B'], Encoded Label: 3\n",
            "🔍 Segment 49 Speakers: ['B', 'A'], Encoded Label: 3\n"
          ]
        }
      ],
      "source": [
        "# ✅ Debug: Check if all extracted segments have valid labels\n",
        "for i, seg in enumerate(extracted_segments[:50]):  # First 10 samples\n",
        "    label = power_set_encoding(seg[\"speakers\"])\n",
        "    print(f\"🔍 Segment {i} Speakers: {seg['speakers']}, Encoded Label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj2S5hularka",
        "outputId": "b8236e6f-0661-439a-bf87-9d23e161d6ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Unique speaker combinations with their frequencies:\n",
            "('A', 'B'): 13279 occurrences\n",
            "('B', 'B'): 43 occurrences\n",
            "('A', 'A'): 36 occurrences\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "all_speaker_labels = [tuple(sorted(seg[\"speakers\"])) for seg in extracted_segments]\n",
        "speaker_count = Counter(all_speaker_labels)\n",
        "\n",
        "print(\"\\n🔍 Unique speaker combinations with their frequencies:\")\n",
        "for speakers, count in speaker_count.items():\n",
        "    print(f\"{speakers}: {count} occurrences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CZxy2xMaxMS",
        "outputId": "7b12938e-a87e-41db-e97b-177bf6fcddd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 How often do 'A1' and 'B1' appear separately or together?\n",
            "('A', 'B'): 13279 occurrences\n",
            "('B', 'B'): 43 occurrences\n",
            "('A', 'A'): 36 occurrences\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n🔍 How often do 'A1' and 'B1' appear separately or together?\")\n",
        "for speakers, count in speaker_count.items():\n",
        "    if \"A\" in speakers or \"B\" in speakers:\n",
        "        print(f\"{speakers}: {count} occurrences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e8OAYdxFT-Y",
        "outputId": "b13cc23e-68ff-43ad-eb61-70924c37abcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset contains 140 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/librosa/core/intervals.py:15: DeprecationWarning: path is deprecated. Use files() instead. Refer to https://importlib-resources.readthedocs.io/en/latest/using.html#migrating-from-legacy for migration advice.\n",
            "  with resources.path(\"librosa.core\", \"intervals.msgpack\") as imsgpack:\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1600\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1920\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1921\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1761\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1616\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1601\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1760\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1759\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1919\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1745\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1904\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1744\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1936\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1935\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total segments with features: 13358\n"
          ]
        }
      ],
      "source": [
        "# Load dataset for retrieving full audio samples\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"talkbank/callhome\", \"eng\", split=\"data\")\n",
        "print(f\"Original dataset contains {len(dataset)} samples.\")\n",
        "\n",
        "# **Feature Extraction Function**\n",
        "def extract_log_mel_spectrogram(segment):\n",
        "    \"\"\"Extracts Log-Mel Spectrogram features for input to SEND model.\"\"\"\n",
        "    source_idx = segment.get(\"source\")\n",
        "    if source_idx is None or source_idx < 0 or source_idx >= len(dataset):\n",
        "        raise ValueError(\"Invalid source index in segment.\")\n",
        "\n",
        "    sample = dataset[source_idx]\n",
        "    audio_info = sample[\"audio\"]\n",
        "    audio_array = audio_info[\"array\"]\n",
        "    sr = audio_info[\"sampling_rate\"]\n",
        "\n",
        "    start_time = segment[\"timestamp_start\"]\n",
        "    end_time = segment[\"timestamp_end\"]\n",
        "    start_sample = int(start_time * sr)\n",
        "    end_sample = int(end_time * sr)\n",
        "    snippet = audio_array[start_sample:end_sample]\n",
        "\n",
        "    # Pad if too short\n",
        "    min_length = sr // 10  # 100ms minimum\n",
        "    if len(snippet) < min_length:\n",
        "        snippet = np.pad(snippet, (0, min_length - len(snippet)), mode='constant')\n",
        "\n",
        "    # Compute Log-Mel Spectrogram\n",
        "    mel_spec = librosa.feature.melspectrogram(y=snippet, sr=sr, n_mels=80)\n",
        "    log_mel = librosa.power_to_db(mel_spec)\n",
        "    log_mel = torch.tensor(log_mel.T, dtype=torch.float32)  # Shape: [time, features]\n",
        "\n",
        "    return log_mel\n",
        "\n",
        "# **Prepare dataset for training**\n",
        "segment_features = []\n",
        "segment_labels = []\n",
        "for seg in extracted_segments:\n",
        "    try:\n",
        "        feat = extract_log_mel_spectrogram(seg)\n",
        "        label = power_set_encoding(seg[\"speakers\"])\n",
        "        segment_features.append(feat)\n",
        "        segment_labels.append(label)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping segment due to error: {e}\")\n",
        "\n",
        "print(f\"Total segments with features: {len(segment_features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14FujepPFh4L"
      },
      "source": [
        "# Define Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc7nl2pnFf2H",
        "outputId": "10585918-d3eb-4fbd-95f1-3a61fbe9969e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Filtered dataset size: 13358 samples\n",
            "✅ Filtered labels size: 13358 labels\n",
            "🔹 Sample 0: Feature Shape: torch.Size([11, 80]), Label: 3\n",
            "🔹 Sample 1: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "🔹 Sample 2: Feature Shape: torch.Size([12, 80]), Label: 3\n",
            "🔹 Sample 3: Feature Shape: torch.Size([42, 80]), Label: 3\n",
            "🔹 Sample 4: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "✅ Train size: 12022, Test size: 1336\n"
          ]
        }
      ],
      "source": [
        "# **Dataset Class**\n",
        "class OverlappingSpeechDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self.features) or self.features[idx] is None or self.labels[idx] is None:\n",
        "            print(f\"⚠️ Warning: Invalid sample at index {idx}. Feature or Label is None.\")\n",
        "            return None  # Prevent errors\n",
        "\n",
        "        feature = self.features[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        print(f\"✅ Sample {idx}: Feature Shape: {feature.shape}, Label: {label}\")\n",
        "\n",
        "        return feature, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn_pad(batch):\n",
        "    \"\"\"Pads variable-length sequences to the longest in the batch.\"\"\"\n",
        "    batch = [b for b in batch if b is not None]  # Remove None samples\n",
        "\n",
        "    if len(batch) == 0:\n",
        "        return None, None  # Return empty batch if all are invalid\n",
        "\n",
        "    features, labels = zip(*batch)\n",
        "\n",
        "    # Pad sequences to the maximum length in this batch\n",
        "    features_padded = pad_sequence(features, batch_first=True, padding_value=0)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return features_padded, labels\n",
        "\n",
        "# **Filter out None values before creating dataset**\n",
        "filtered_features = [feat for feat, lbl in zip(segment_features, segment_labels) if feat is not None and lbl is not None]\n",
        "filtered_labels = [lbl for feat, lbl in zip(segment_features, segment_labels) if feat is not None and lbl is not None]\n",
        "\n",
        "# ✅ Debug: Check if filtering removed everything\n",
        "print(f\"✅ Filtered dataset size: {len(filtered_features)} samples\")\n",
        "print(f\"✅ Filtered labels size: {len(filtered_labels)} labels\")\n",
        "\n",
        "if len(filtered_features) == 0:\n",
        "    raise ValueError(\"🚨 No valid samples left after filtering! Check how power_set_encoding() assigns labels.\")\n",
        "\n",
        "# ✅ Print first few valid samples to verify\n",
        "for i in range(min(5, len(filtered_features))):  # Print only available samples\n",
        "    print(f\"🔹 Sample {i}: Feature Shape: {filtered_features[i].shape}, Label: {filtered_labels[i]}\")\n",
        "\n",
        "# **Split dataset for Federated Learning**\n",
        "train_val_size = int(0.9 * len(filtered_features))\n",
        "final_test_size = len(filtered_features) - train_val_size\n",
        "\n",
        "train_val_dataset, final_test_dataset = random_split(filtered_features, [train_val_size, final_test_size])\n",
        "train_labels, test_labels = filtered_labels[:train_val_size], filtered_labels[train_val_size:]\n",
        "\n",
        "# ✅ Debug: Ensure train/test splits are valid\n",
        "print(f\"✅ Train size: {len(train_val_dataset)}, Test size: {len(final_test_dataset)}\")\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    OverlappingSpeechDataset(train_val_dataset, train_labels),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn_pad\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    OverlappingSpeechDataset(final_test_dataset, test_labels),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn_pad\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9ROPO-uFpo-"
      },
      "source": [
        "# Define SEND Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9kkNehEfBlt9"
      },
      "outputs": [],
      "source": [
        "num_speakers=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xur266jFv-K"
      },
      "source": [
        "# Federated Learning Client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"🔍 Unique Encoded Labels: {set(segment_labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHIgfqtlNrkH",
        "outputId": "4c0f2e39-5455-4da7-fc42-74655f4c5535"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Unique Encoded Labels: {1, 2, 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "frpgijwpFu8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352479c1-1c7d-49ab-b17e-154cb89bf6f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  stats = torch.load(path, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "WARNING:flwr:DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=2, no round_timeout\n",
            "2025-02-24 20:10:53,414\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 4.0, 'object_store_memory': 3992109465.0, 'node:172.28.0.12': 1.0, 'memory': 7984218932.0, 'node:__internal_head__': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 4 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=63097)\u001b[0m 2025-02-24 20:11:05.059000: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=63097)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=63097)\u001b[0m E0000 00:00:1740427865.144491   63097 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=63097)\u001b[0m E0000 00:00:1740427865.161491   63097 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m /usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m   wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "\u001b[36m(pid=63124)\u001b[0m 2025-02-24 20:11:05.494195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(pid=63124)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=63124)\u001b[0m E0000 00:00:1740427865.581410   63124 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=63124)\u001b[0m E0000 00:00:1740427865.608874   63124 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:Training on cpu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11492: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2257: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2415: Feature Shape: torch.Size([15, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11027: Feature Shape: torch.Size([29, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3328: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 994: Feature Shape: torch.Size([18, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6582: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7612: Feature Shape: torch.Size([46, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11095: Feature Shape: torch.Size([23, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11886: Feature Shape: torch.Size([23, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7087: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1916: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5140: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4540: Feature Shape: torch.Size([33, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2007: Feature Shape: torch.Size([34, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8999: Feature Shape: torch.Size([22, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10137: Feature Shape: torch.Size([6, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8502: Feature Shape: torch.Size([7, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8692: Feature Shape: torch.Size([21, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9488: Feature Shape: torch.Size([15, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3953: Feature Shape: torch.Size([17, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11972: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11180: Feature Shape: torch.Size([5, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2981: Feature Shape: torch.Size([14, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11695: Feature Shape: torch.Size([27, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10208: Feature Shape: torch.Size([5, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 522: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5106: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1481: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11217: Feature Shape: torch.Size([14, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5958: Feature Shape: torch.Size([5, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 810: Feature Shape: torch.Size([16, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11469: Feature Shape: torch.Size([17, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7444: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 457: Feature Shape: torch.Size([10, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5827: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8191: Feature Shape: torch.Size([15, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3928: Feature Shape: torch.Size([31, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4231: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10260: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 165: Feature Shape: torch.Size([61, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7686: Feature Shape: torch.Size([12, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8207: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2300: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 900: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7662: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2900: Feature Shape: torch.Size([27, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4629: Feature Shape: torch.Size([10, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3337: Feature Shape: torch.Size([12, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2529: Feature Shape: torch.Size([29, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5428: Feature Shape: torch.Size([12, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1028: Feature Shape: torch.Size([16, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6744: Feature Shape: torch.Size([5, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11749: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10620: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8528: Feature Shape: torch.Size([23, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11086: Feature Shape: torch.Size([13, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4477: Feature Shape: torch.Size([20, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8947: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2166: Feature Shape: torch.Size([6, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9167: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3997: Feature Shape: torch.Size([17, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9553: Feature Shape: torch.Size([12, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11694: Feature Shape: torch.Size([4, 80]), Label: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m /usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m   wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8619: Feature Shape: torch.Size([12, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5453: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11535: Feature Shape: torch.Size([5, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 358: Feature Shape: torch.Size([12, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5627: Feature Shape: torch.Size([16, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3156: Feature Shape: torch.Size([35, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2020: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2880: Feature Shape: torch.Size([7, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11456: Feature Shape: torch.Size([11, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10145: Feature Shape: torch.Size([16, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5766: Feature Shape: torch.Size([28, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7337: Feature Shape: torch.Size([27, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2815: Feature Shape: torch.Size([20, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7477: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6934: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1872: Feature Shape: torch.Size([7, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6055: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5112: Feature Shape: torch.Size([10, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5196: Feature Shape: torch.Size([20, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1802: Feature Shape: torch.Size([6, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9530: Feature Shape: torch.Size([25, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10114: Feature Shape: torch.Size([15, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5798: Feature Shape: torch.Size([21, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3417: Feature Shape: torch.Size([17, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11561: Feature Shape: torch.Size([7, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4240: Feature Shape: torch.Size([7, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10976: Feature Shape: torch.Size([31, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5425: Feature Shape: torch.Size([15, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11705: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4384: Feature Shape: torch.Size([15, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9299: Feature Shape: torch.Size([22, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5739: Feature Shape: torch.Size([14, 80]), Label: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m /usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m   wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m /usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m   wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2749: Feature Shape: torch.Size([16, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8656: Feature Shape: torch.Size([6, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3878: Feature Shape: torch.Size([48, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10249: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4161: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1064: Feature Shape: torch.Size([11, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3062: Feature Shape: torch.Size([19, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11772: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8745: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1166: Feature Shape: torch.Size([26, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5573: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11483: Feature Shape: torch.Size([6, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1246: Feature Shape: torch.Size([10, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3828: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11164: Feature Shape: torch.Size([20, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7133: Feature Shape: torch.Size([12, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5507: Feature Shape: torch.Size([17, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6483: Feature Shape: torch.Size([15, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11632: Feature Shape: torch.Size([34, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7063: Feature Shape: torch.Size([7, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5602: Feature Shape: torch.Size([10, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 44: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6810: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2053: Feature Shape: torch.Size([17, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5195: Feature Shape: torch.Size([38, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2778: Feature Shape: torch.Size([24, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11071: Feature Shape: torch.Size([15, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1647: Feature Shape: torch.Size([16, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5371: Feature Shape: torch.Size([64, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1511: Feature Shape: torch.Size([35, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9494: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10230: Feature Shape: torch.Size([4, 80]), Label: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11250: Feature Shape: torch.Size([13, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1499: Feature Shape: torch.Size([7, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5650: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11162: Feature Shape: torch.Size([11, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11288: Feature Shape: torch.Size([10, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7215: Feature Shape: torch.Size([11, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9437: Feature Shape: torch.Size([25, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8830: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9136: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11721: Feature Shape: torch.Size([5, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1208: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9998: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8160: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5076: Feature Shape: torch.Size([35, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4559: Feature Shape: torch.Size([7, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4524: Feature Shape: torch.Size([4, 80]), Label: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:Training on cpu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9235: Feature Shape: torch.Size([10, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3265: Feature Shape: torch.Size([104, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10025: Feature Shape: torch.Size([14, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2656: Feature Shape: torch.Size([6, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6170: Feature Shape: torch.Size([5, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6646: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3456: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11820: Feature Shape: torch.Size([16, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5582: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7414: Feature Shape: torch.Size([5, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4522: Feature Shape: torch.Size([9, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4058: Feature Shape: torch.Size([13, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4381: Feature Shape: torch.Size([4, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9516: Feature Shape: torch.Size([26, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7687: Feature Shape: torch.Size([8, 80]), Label: 3\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1000: Feature Shape: torch.Size([15, 80]), Label: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:Using device: cpu\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5410: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 32x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:Training on cpu...\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4937: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5283: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6316: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4758: Feature Shape: torch.Size([39, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5217: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6054: Feature Shape: torch.Size([70, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10834: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11199: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5008: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5119: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5798: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 882: Feature Shape: torch.Size([50, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1717: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11911: Feature Shape: torch.Size([32, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1801: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10197: Feature Shape: torch.Size([49, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6259: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6451: Feature Shape: torch.Size([90, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3567: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10180: Feature Shape: torch.Size([24, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2851: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5003: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9139: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2594: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6380: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7249: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3219: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7430: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2350: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9322: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9276: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5870: Feature Shape: torch.Size([46, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11925: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2586: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9120: Feature Shape: torch.Size([29, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11669: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2384: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 7803: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 122x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1481: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10085: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8803: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5227: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5018: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4718: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10348: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11853: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9615: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6010: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4729: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11345: Feature Shape: torch.Size([24, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8042: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8283: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10873: Feature Shape: torch.Size([50, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6549: Feature Shape: torch.Size([24, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1000: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7432: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5706: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2296: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3806: Feature Shape: torch.Size([38, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11590: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5135: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8630: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9017: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4914: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3004: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7546: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 95x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11361: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11297: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4230: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4562: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 7883: Feature Shape: torch.Size([28, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6328: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9375: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3367: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10301: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7011: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4246: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1907: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1876: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11787: Feature Shape: torch.Size([49, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11620: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5001: Feature Shape: torch.Size([50, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8289: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 662: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7718: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9081: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7614: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3421: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5261: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5620: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10410: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 636: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5641: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4310: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4538: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3696: Feature Shape: torch.Size([45, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8078: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10404: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11532: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1475: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11543: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8938: Feature Shape: torch.Size([52, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 256: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8153: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3589: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 95: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1352: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4949: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5024: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10825: Feature Shape: torch.Size([42, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 7909: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7758: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11153: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1213: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2823: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11319: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 310: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5946: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3353: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1675: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11155: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1414: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10220: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11556: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1868: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5424: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 12008: Feature Shape: torch.Size([46, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2302: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1453: Feature Shape: torch.Size([24, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4704: Feature Shape: torch.Size([31, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 541: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8301: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 431: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1999: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1705: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5174: Feature Shape: torch.Size([38, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5913: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3275: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3364: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 944: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 683: Feature Shape: torch.Size([28, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6624: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11541: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5308: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5685: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8338: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3940: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4142: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6820: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1044: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7204: Feature Shape: torch.Size([50, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8206: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1128: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 630: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3406: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4412: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11220: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2061: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1588: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2506: Feature Shape: torch.Size([31, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5924: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3779: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6553: Feature Shape: torch.Size([92, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4390: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9135: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3541: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8441: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4441: Feature Shape: torch.Size([29, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2390: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8260: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6911: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11095: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 131: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8932: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2947: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7762: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8901: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3911: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8646: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 12008: Feature Shape: torch.Size([46, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4736: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5296: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8800: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11568: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3400: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8734: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4314: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2214: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2582: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10226: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1116: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8684: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4488: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9251: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7477: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4203: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3055: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10530: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9128: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1485: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5653: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7657: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6570: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11486: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11352: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9025: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2293: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7320: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10147: Feature Shape: torch.Size([41, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1784: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9517: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4584: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10966: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3055: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1664: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8156: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11694: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5432: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7580: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8268: Feature Shape: torch.Size([37, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3889: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6709: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4957: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 845: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1011: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10755: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4733: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1527: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4255: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5969: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3367: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11776: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10864: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5288: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5127: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8188: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10455: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 176x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9432: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3572: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8395: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3931: Feature Shape: torch.Size([41, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11038: Feature Shape: torch.Size([53, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5051: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3889: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8628: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5539: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3482: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9750: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7039: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3153: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4208: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7805: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2141: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 511: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4395: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2440: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5689: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6068: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4199: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4997: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6380: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8706: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11726: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1483: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8428: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2767: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 810: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2102: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10423: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10314: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10520: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6980: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7337: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10073: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3155: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 60: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2737: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9616: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 824: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11248: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7919: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3284: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 113x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11133: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 111x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9833: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1697: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7974: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2183: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3773: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 984: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2157: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2860: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 247: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 176x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1686: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9686: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4756: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8499: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4447: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11602: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 996: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11475: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3472: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3617: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11724: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 102: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7324: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3365: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1493: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4295: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6917: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2400: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 430: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3125: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1866: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10091: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10370: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9222: Feature Shape: torch.Size([72, 80]), Label: 3\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 249: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9217: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6240: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9479: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 691: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5839: Feature Shape: torch.Size([34, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1264: Feature Shape: torch.Size([30, 80]), Label: 3\u001b[32m [repeated 75x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8218: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 133x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9449: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10044: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 373: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4248: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2067: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11129: Feature Shape: torch.Size([24, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11434: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 698: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10377: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11163: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2036: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9627: Feature Shape: torch.Size([39, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5891: Feature Shape: torch.Size([4, 80]), Label: 2\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1267: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8991: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5806: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8658: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8535: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6319: Feature Shape: torch.Size([31, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10466: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10856: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4019: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 176x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10477: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9160: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 192x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11216: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11170: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 655: Feature Shape: torch.Size([23, 80]), Label: 2\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7488: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8423: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2707: Feature Shape: torch.Size([30, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10924: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 62: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8346: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 68x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 608: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 124x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7263: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6567: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7328: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7352: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 192x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3159: Feature Shape: torch.Size([48, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6406: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7175: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 452: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6474: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11107: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7401: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9067: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10901: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8833: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11782: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 815: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9919: Feature Shape: torch.Size([46, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5416: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11808: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7442: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7367: Feature Shape: torch.Size([30, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5760: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4463: Feature Shape: torch.Size([50, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 697: Feature Shape: torch.Size([33, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10116: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1957: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1501: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9362: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9777: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 508: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3744: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5458: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1574: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5402: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2012: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 120: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1399: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5518: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5547: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1339: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6482: Feature Shape: torch.Size([28, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10240: Feature Shape: torch.Size([53, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3202: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3272: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1495: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3390: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9571: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9127: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9518: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3368: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 103x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9155: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 121x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4042: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8115: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 12011: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7716: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11047: Feature Shape: torch.Size([65, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5177: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 86x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9684: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3832: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2859: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1914: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9718: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9764: Feature Shape: torch.Size([46, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 741: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9404: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8625: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6569: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11139: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4143: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8238: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5743: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10785: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8077: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:Training on cpu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 15: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 38x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 0\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.00567780714482069\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 1\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.00563402334228158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 47: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 32x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 2\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.38398438692092896\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 3\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005724783055484295\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 4\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.00562216155230999\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 5\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005712730810046196\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 6\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.00579498615115881\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 7\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005806646775454283\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 8\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005626651458442211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 159: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 9\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005750919226557016\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 10\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005724679678678513\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 11\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005723901558667421\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Batch Loss: 0.00567780714482069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 79: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 224x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:Using device: cpu\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 13\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.00562216155230999\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 143: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 224x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 8\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.005750919226557016\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 159: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 352x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Evaluation Batch 10\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.005588621366769075\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 479: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 336x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Evaluation Batch 14\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005624709650874138\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 527: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 256x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Evaluation Batch 18\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Batch Loss: 0.0058284904807806015\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 479: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 352x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 38\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005745992995798588\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 559: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 368x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 41\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.005678881891071796\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 607: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 208x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Evaluation Batch 39\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.005764312110841274\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 607: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 336x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Evaluation Batch 44\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005611196625977755\u001b[32m [repeated 23x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 895: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 384x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Evaluation Batch 42\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005736813880503178\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 751: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 176x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 51\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.005700706038624048\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 831: Feature Shape: torch.Size([52, 80]), Label: 3\u001b[32m [repeated 352x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 63\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Batch Loss: 0.005908783059567213\u001b[32m [repeated 26x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 927: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 384x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 69\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Batch Loss: 0.005625213962048292\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1087: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 208x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 67\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.005672592204064131\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1071: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 288x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 73\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Batch Loss: 0.00582889886572957\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1335: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 408x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:✅ Evaluation Results - Loss: 0.0280, Accuracy: 99.63%\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Evaluation Batch 73\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.005783579312264919\u001b[32m [repeated 25x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1295: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 288x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:✅ Evaluation Results - Loss: 0.0280, Accuracy: 99.63%\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Evaluation Batch 83\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Batch Loss: 0.005783579312264919\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:✅ Evaluation Results - Loss: 0.0280, Accuracy: 99.63%\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:Training on cpu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6075: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9890: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 32x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:Training on cpu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6264: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 757: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6222: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1963: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7840: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3541: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3423: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3553: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7116: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9817: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1408: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9175: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6076: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4757: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4095: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3793: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1878: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8066: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2699: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2004: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9240: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10857: Feature Shape: torch.Size([31, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3013: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 89x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 19: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 103x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5796: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4962: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 675: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11775: Feature Shape: torch.Size([49, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11933: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1194: Feature Shape: torch.Size([4, 80]), Label: 1\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 204: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9914: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11477: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8337: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11333: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5906: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6858: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8811: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6026: Feature Shape: torch.Size([33, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 564: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 247: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6543: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4931: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4825: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3242: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6217: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 659: Feature Shape: torch.Size([8, 80]), Label: 2\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1134: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6521: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8749: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 931: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 129x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4303: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 111x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7964: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6261: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3168: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 434: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6963: Feature Shape: torch.Size([39, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10256: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10118: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2784: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11330: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7668: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6156: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3157: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4404: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9243: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 169: Feature Shape: torch.Size([29, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6620: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11350: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2470: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 463: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3104: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8114: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11190: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6618: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1435: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7118: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1180: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4559: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 995: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9339: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 482: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11703: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 129x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10257: Feature Shape: torch.Size([55, 80]), Label: 3\u001b[32m [repeated 127x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7186: Feature Shape: torch.Size([35, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10411: Feature Shape: torch.Size([30, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4144: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9997: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5805: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6130: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10830: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6600: Feature Shape: torch.Size([10, 80]), Label: 2\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9827: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10129: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5809: Feature Shape: torch.Size([38, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11993: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11926: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 145x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6010: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 95x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10372: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8944: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3305: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1287: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7240: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9581: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6862: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8449: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6197: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4939: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9556: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8834: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11929: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 225: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 497: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1882: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5789: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1214: Feature Shape: torch.Size([41, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3750: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6400: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2679: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3641: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 130x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2397: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 142x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10812: Feature Shape: torch.Size([32, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5316: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3183: Feature Shape: torch.Size([57, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 355: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11277: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5069: Feature Shape: torch.Size([24, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5372: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8450: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11201: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8300: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10245: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2818: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 261: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11723: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10593: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3951: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10948: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4859: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9017: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 67x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6251: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 141x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4765: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1426: Feature Shape: torch.Size([103, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7568: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11547: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8664: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8608: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3014: Feature Shape: torch.Size([35, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6303: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2257: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6590: Feature Shape: torch.Size([29, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1798: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4366: Feature Shape: torch.Size([55, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9955: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1116: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10987: Feature Shape: torch.Size([41, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6167: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7733: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6654: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7705: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4280: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5946: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3522: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2640: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1032: Feature Shape: torch.Size([50, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11912: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3051: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9121: Feature Shape: torch.Size([19, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4416: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3517: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2644: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2702: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 805: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11900: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11114: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7550: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8331: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1230: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 932: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1004: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9450: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10661: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6165: Feature Shape: torch.Size([100, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6720: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11164: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2370: Feature Shape: torch.Size([28, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2337: Feature Shape: torch.Size([80, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8080: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4539: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10762: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3842: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3215: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2515: Feature Shape: torch.Size([28, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2885: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 2079: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2309: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3377: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 8819: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10556: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3882: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11214: Feature Shape: torch.Size([38, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10578: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9749: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4261: Feature Shape: torch.Size([42, 80]), Label: 3\u001b[32m [repeated 116x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7611: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4213: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10161: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3039: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1415: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8343: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9827: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4399: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6550: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1263: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3000: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4922: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6174: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2898: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 515: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7354: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11527: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6737: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1100: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 856: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3324: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10231: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10719: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9803: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4798: Feature Shape: torch.Size([62, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10426: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3534: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10565: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10642: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4371: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10497: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5567: Feature Shape: torch.Size([31, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2235: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5956: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3178: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10391: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7535: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 630: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3264: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8230: Feature Shape: torch.Size([29, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7113: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10224: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 176x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8124: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1906: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4209: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 7770: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9403: Feature Shape: torch.Size([24, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9415: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 14: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10967: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5477: Feature Shape: torch.Size([45, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11495: Feature Shape: torch.Size([37, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 6018: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9845: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4047: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9986: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5302: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11958: Feature Shape: torch.Size([21, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11082: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2493: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3000: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 819: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11434: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 75x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8404: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 117x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8703: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11990: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6439: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 634: Feature Shape: torch.Size([4, 80]), Label: 2\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6788: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11229: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11268: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8582: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5319: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3319: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6703: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 176x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2709: Feature Shape: torch.Size([28, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4508: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5681: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4746: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4135: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 12003: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6365: Feature Shape: torch.Size([35, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8285: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1040: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8184: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4344: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11037: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11489: Feature Shape: torch.Size([22, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7699: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 12005: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5530: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5599: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1777: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9376: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 11557: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8769: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11141: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 132x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4193: Feature Shape: torch.Size([66, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6995: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2845: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 450: Feature Shape: torch.Size([38, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11266: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5246: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2698: Feature Shape: torch.Size([31, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11057: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7633: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10293: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 7527: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4744: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4717: Feature Shape: torch.Size([46, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8824: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5785: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4719: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 83: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2867: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6402: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 131x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10358: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 77x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11559: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9964: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5075: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10202: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7000: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 7938: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4595: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2184: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10733: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1499: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4484: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 264: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 5453: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11925: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10359: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1585: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10201: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11760: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 182: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4294: Feature Shape: torch.Size([41, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3629: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3613: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5311: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6802: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 108x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7681: Feature Shape: torch.Size([78, 80]), Label: 3\u001b[32m [repeated 164x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 11491: Feature Shape: torch.Size([25, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8945: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5823: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9362: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 11485: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5730: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6772: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 10783: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2761: Feature Shape: torch.Size([24, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4752: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8851: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10523: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1252: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8107: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1411: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6778: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1082: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1670: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 2371: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 4863: Feature Shape: torch.Size([30, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1419: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6235: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1226: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6490: Feature Shape: torch.Size([165, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7216: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 945: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 4001: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 937: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10939: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1535: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 10828: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 97: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3715: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2142: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1637: Feature Shape: torch.Size([26, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4045: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1078: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 103: Feature Shape: torch.Size([32, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 3253: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5674: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11816: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9578: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6573: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 193: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 7184: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 9366: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 8157: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9506: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 6960: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6617: Feature Shape: torch.Size([23, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 4973: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 9173: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 10528: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1638: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 7143: Feature Shape: torch.Size([7, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10768: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8734: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5496: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3578: Feature Shape: torch.Size([45, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 11671: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5129: Feature Shape: torch.Size([15, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 8553: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 5796: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 160x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 3076: Feature Shape: torch.Size([28, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4979: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 4049: Feature Shape: torch.Size([54, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 462: Feature Shape: torch.Size([59, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 3670: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 5150: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 6519: Feature Shape: torch.Size([45, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 6274: Feature Shape: torch.Size([11, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 10276: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 203: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2556: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 1481: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5476: Feature Shape: torch.Size([27, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 9319: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 9407: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 7421: Feature Shape: torch.Size([9, 80]), Label: 3\u001b[32m [repeated 80x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2382: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 2360: Feature Shape: torch.Size([5, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 8886: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7440: Feature Shape: torch.Size([10, 80]), Label: 3\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 7552: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 118x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 5020: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 2334: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 7480: Feature Shape: torch.Size([16, 80]), Label: 3\u001b[32m [repeated 118x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 3681: Feature Shape: torch.Size([33, 80]), Label: 3\u001b[32m [repeated 112x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:Training on cpu...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:Using device: cpu\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 15: Feature Shape: torch.Size([14, 80]), Label: 3\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 0\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.01157512329518795\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 1\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.01150911021977663\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 2\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.3271968960762024\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 3\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011640682816505432\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 4\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011492624878883362\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 5\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011621852405369282\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 6\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.01173867005854845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 143: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 7\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011754477396607399\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 8\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011500676162540913\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 9\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011672304943203926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 191: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 48x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 10\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011640661396086216\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 11\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.0116406986489892\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 12\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011375898495316505\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 13\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011445648968219757\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 14\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011640528216958046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 47: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 128x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Evaluation Batch 0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Batch Loss: 0.01157512329518795\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 47: Feature Shape: torch.Size([12, 80]), Label: 3\u001b[32m [repeated 208x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:Using device: cpu\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m WARNING:flwr:Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 9\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.011672304943203926\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 63: Feature Shape: torch.Size([17, 80]), Label: 3\u001b[32m [repeated 288x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Evaluation Batch 5\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Batch Loss: 0.011621852405369282\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 511: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 336x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 34\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011771377176046371\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 367: Feature Shape: torch.Size([13, 80]), Label: 3\u001b[32m [repeated 272x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Evaluation Batch 17\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Batch Loss: 0.01165065448731184\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 671: Feature Shape: torch.Size([18, 80]), Label: 3\u001b[32m [repeated 288x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Evaluation Batch 23\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Batch Loss: 0.011425207369029522\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 415: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 336x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Evaluation Batch 27\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Batch Loss: 0.011533166281878948\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 799: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 304x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 50\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011500588618218899\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 591: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 352x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Evaluation Batch 56\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:🔹 Batch Loss: 0.011661458760499954\u001b[32m [repeated 25x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 687: Feature Shape: torch.Size([6, 80]), Label: 3\u001b[32m [repeated 336x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 45\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.011738844215869904\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m ✅ Sample 1023: Feature Shape: torch.Size([31, 80]), Label: 3\u001b[32m [repeated 208x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 48\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.011709962971508503\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 815: Feature Shape: torch.Size([4, 80]), Label: 3\u001b[32m [repeated 320x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 53\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Batch Loss: 0.011901325546205044\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 927: Feature Shape: torch.Size([20, 80]), Label: 3\u001b[32m [repeated 336x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:🔹 Evaluation Batch 59\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Batch Loss: 0.011613220907747746\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m ✅ Sample 975: Feature Shape: torch.Size([32, 80]), Label: 3\u001b[32m [repeated 272x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Evaluation Batch 61\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Batch Loss: 0.011596892960369587\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1055: Feature Shape: torch.Size([31, 80]), Label: 3\u001b[32m [repeated 320x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63044)\u001b[0m INFO:root:✅ Evaluation Results - Loss: 0.0306, Accuracy: 99.63%\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Evaluation Batch 68\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m INFO:root:🔹 Batch Loss: 0.011549877002835274\u001b[32m [repeated 25x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m ✅ Sample 1199: Feature Shape: torch.Size([36, 80]), Label: 3\u001b[32m [repeated 344x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Evaluation Batch 74\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Batch Loss: 0.011568386107683182\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=63124)\u001b[0m ✅ Sample 1231: Feature Shape: torch.Size([8, 80]), Label: 3\u001b[32m [repeated 240x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=63043)\u001b[0m INFO:root:✅ Evaluation Results - Loss: 0.0306, Accuracy: 99.63%\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Evaluation Batch 79\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Predictions: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Ground Truth: tensor([3, 3, 3, 3, 3])\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=63097)\u001b[0m INFO:root:🔹 Batch Loss: 0.011604604311287403\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 2 round(s) in 5223.54s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.027965324088221506\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.030552221428869025\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.027965324088221506\n",
              "\tround 2: 0.030552221428869025"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import logging\n",
        "import time\n",
        "import flwr as fl\n",
        "\n",
        "import importlib\n",
        "import ray\n",
        "importlib.reload(ray)\n",
        "\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ Define `speaker_encoder` correctly\n",
        "speaker_encoder = EncoderClassifier.from_hparams(\n",
        "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    savedir=\"pretrained_models/spkrec-ecapa\",\n",
        "    run_opts={\"device\": DEVICE}\n",
        ").to(DEVICE)\n",
        "\n",
        "# **SEND Model**\n",
        "class SpeechEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        return x\n",
        "\n",
        "class SEND(nn.Module):\n",
        "    def __init__(self, input_dim, speaker_dim, hidden_dim, num_layers, num_speakers):\n",
        "        super().__init__()\n",
        "        self.speech_encoder = SpeechEncoder(input_dim, hidden_dim, num_layers)\n",
        "        self.speaker_encoder = speaker_encoder.encode_batch\n",
        "\n",
        "        self.feature_projection = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n",
        "        self.context_independent = nn.Linear(hidden_dim * 2, num_speakers)\n",
        "        self.context_dependent = nn.TransformerEncoder(nn.TransformerEncoderLayer(hidden_dim * 2, 4), num_layers)\n",
        "        self.match_projection = nn.Linear(hidden_dim * 2, num_speakers)\n",
        "        self.post_net = nn.Linear(hidden_dim * 2, 2 ** num_speakers)  # Ensure input matches hidden_dim * 2\n",
        "\n",
        "    def forward(self, speech):\n",
        "        # Ensure correct shape\n",
        "        if speech.dim() == 4:\n",
        "            speech = speech.squeeze(1)\n",
        "\n",
        "        speech_features = self.speech_encoder(speech)\n",
        "        # print(f\"🔹 Speech features shape after LSTM: {speech_features.shape}\")  # [16, 29, 512]\n",
        "\n",
        "        speech_features = self.feature_projection(speech_features)\n",
        "        # print(f\"🔹 Projected speech features shape: {speech_features.shape}\")  # [16, 29, 512]\n",
        "\n",
        "        # **Apply mean pooling across time dimension (sequence length 29)**\n",
        "        pooled_features = torch.mean(speech_features, dim=1)  # [16, 512]\n",
        "        # print(f\"🔹 Pooled features shape: {pooled_features.shape}\")  # [16, 512]\n",
        "\n",
        "        # Ensure output matches batch size\n",
        "        output = self.post_net(pooled_features)  # [16, num_classes]\n",
        "        # print(f\"🔹 Model output shape: {output.shape}\")  # Should be [16, 2**num_speakers]\n",
        "\n",
        "        return output\n",
        "\n",
        "model = SEND(input_dim=80, speaker_dim=512, hidden_dim=256, num_layers=4, num_speakers=num_speakers).to(DEVICE)\n",
        "\n",
        "class FLClient(NumPyClient):\n",
        "    def __init__(self, model, train_loader, test_loader):\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # ✅ Force CPU globally\n",
        "        self.device = torch.device(\"cpu\")  # ✅ Force CPU for PyTorch\n",
        "        logging.info(f\"Using device: {self.device}\")\n",
        "        self.model = model.to(self.device)  # ✅ Move model to CPU\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def get_parameters(self, config=None):\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        state_dict = {k: torch.tensor(v).to(self.device) for k, v in zip(self.model.state_dict().keys(), parameters)}\n",
        "        self.model.load_state_dict(state_dict)\n",
        "        self.model.to(self.device)  # Ensure model is on the right device\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.train()\n",
        "\n",
        "        logging.info(f\"Training on {self.device}...\")\n",
        "        for epoch in range(1):\n",
        "            for batch_idx, (features, labels) in enumerate(self.train_loader):\n",
        "                features, labels = features.to(self.device), labels.to(self.device)  # ✅ Force CPU usage\n",
        "                # print(f\"Labels shape: {labels.shape}\")  # Check shape\n",
        "                # print(f\"Sample labels: {labels[:5]}\")  # Print first 5 labels\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(features)  # Should return (batch_size, num_classes)\n",
        "                # print(f\"Outputs shape: {outputs.shape}\")  # Expected: [16, num_classes]\n",
        "                # print(f\"🔹 Labels shape before expansion: {labels.shape}\")\n",
        "                labels = labels.view(-1)  # Ensure correct shape\n",
        "                # print(f\"✅ Final Labels shape: {labels.shape}\")  # Should be [16]\n",
        "\n",
        "                loss = self.criterion(outputs, labels.long())  # Ensure it matches [16]\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "        return self.get_parameters(), len(self.train_loader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.eval()\n",
        "\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (features, labels) in enumerate(self.test_loader):\n",
        "                features, labels = features.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(features)\n",
        "\n",
        "                labels = labels.long()\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "                preds = torch.argmax(outputs, dim=-1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.numel()\n",
        "\n",
        "                # ✅ Add debug logging for evaluation\n",
        "                logging.info(f\"🔹 Evaluation Batch {batch_idx}\")\n",
        "                logging.info(f\"🔹 Predictions: {preds[:5]}\")\n",
        "                logging.info(f\"🔹 Ground Truth: {labels[:5]}\")\n",
        "                logging.info(f\"🔹 Batch Loss: {loss.item()}\")\n",
        "\n",
        "        accuracy = correct / total if total > 0 else 0.0\n",
        "        logging.info(f\"✅ Evaluation Results - Loss: {total_loss / len(self.test_loader):.4f}, Accuracy: {accuracy:.2%}\")\n",
        "        return total_loss / len(self.test_loader), len(self.test_loader.dataset), {\"accuracy\": accuracy}\n",
        "\n",
        "# ✅ Custom Strategy for Evaluation Debugging\n",
        "class PrintEvaluateStrategy(fl.server.strategy.FedAvg):\n",
        "    def aggregate_evaluate(self, rnd: int, results, failures):\n",
        "        aggregated = super().aggregate_evaluate(rnd, results, failures)\n",
        "        if aggregated is None:\n",
        "            logging.info(f\"[ROUND {rnd}] No evaluation results\")\n",
        "            return aggregated\n",
        "        if isinstance(aggregated, tuple):\n",
        "            if len(aggregated) == 3:\n",
        "                loss, num_examples, metrics = aggregated\n",
        "            elif len(aggregated) == 2:\n",
        "                loss, num_examples = aggregated\n",
        "                num_examples = num_examples if isinstance(num_examples, int) else \"unknown\"\n",
        "                metrics = {}\n",
        "            else:\n",
        "                loss, num_examples, metrics = aggregated, \"unknown\", {}\n",
        "        else:\n",
        "            logging.info(f\"[ROUND {rnd}] Aggregated evaluation: {aggregated}\")\n",
        "            return aggregated\n",
        "\n",
        "        accuracy = metrics.get(\"accuracy\", None)\n",
        "        accuracy_str = f\"{accuracy:.2%}\" if accuracy is not None else \"N/A\"\n",
        "        logging.info(f\"[ROUND {rnd}] Evaluation results: Loss: {loss:.4f}, Accuracy: {accuracy_str} on {num_examples} examples\")\n",
        "        return aggregated\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "strategy = PrintEvaluateStrategy(min_fit_clients=4, min_available_clients=4)\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=lambda ctx: FLClient(model, train_loader, test_loader),\n",
        "    num_clients=4,\n",
        "    config=fl.server.ServerConfig(num_rounds=2),\n",
        "    strategy=fl.server.strategy.FedAvg(),\n",
        "    ray_init_args={\n",
        "        \"num_cpus\": 4,  # ✅ Only use CPU\n",
        "        \"include_dashboard\": False,\n",
        "        \"ignore_reinit_error\": True,\n",
        "    },\n",
        "    client_resources={\"num_cpus\": 1}  # ✅ No GPU needed\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}